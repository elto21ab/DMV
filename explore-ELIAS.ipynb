{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listings shape: (20909, 75)\n",
      "Calendar shape: (7631731, 7)\n",
      "Reviews shape: (366636, 6)\n"
     ]
    }
   ],
   "source": [
    "# Read the CSV files\n",
    "cal = pd.read_csv('data/raw/calendar2024.csv')\n",
    "lis = pd.read_csv('data/raw/listings2024.csv') \n",
    "rev = pd.read_csv('data/raw/reviews2024.csv')\n",
    "print(\"Listings shape:\", lis.shape)\n",
    "print(\"Calendar shape:\", cal.shape) \n",
    "print(\"Reviews shape:\", rev.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "- [ ] Many variables are stored as generic objects, instead of their actual datatype\n",
    "- [ ] datetime columns are stored as objects\n",
    "- [ ] lis.neighbourhood_cleansed has spelling mistakes\n",
    "- [ ] first name of reviewer/host seems irrelevant, when unique-ID is available\n",
    "- [ ] NaN, missing, and null values are inconsistent\n",
    "- [ ] Boolean is expressed as t/f\n",
    "- [ ] Price is stored as a string in an arbitrary currency (is it $ or local?)\n",
    "- [ ] lis csv. host_verifications, and amenities are categorical, but are stored as objects. Depending on how many amenities there are, it may/may not be better to store as a categorical – but host_verification is a short enough list. Same goes for source.\n",
    "\n",
    "**lis csv** \n",
    "- property_type, and room_type are mapped as obj., is categorial\n",
    "- bathroom and bathrooms_text are the same, but bathrooms_text has some values that are not in bathroom.\n",
    "- bedrooms, and beds\tare stored as float, but is int.\n",
    "\n",
    "- [ ] ETL: Extract, Transform, Load\n",
    "\n",
    "---\n",
    "> Attributes of datasets identified at initial look\n",
    "- Primary keys: cal.listing_id, list.id, rev.listing_id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listings shape: (20909, 70)\n",
      "Calendar shape: (7631731, 6)\n",
      "Reviews shape: (366636, 5)\n"
     ]
    }
   ],
   "source": [
    "null_cols_lis = lis.columns[lis.isna().all()].tolist()\n",
    "lis = lis.drop(columns=null_cols_lis)\n",
    "\n",
    "lis.drop(columns=['scrape_id', 'host_name', 'picture_url', 'host_url', 'host_thumbnail_url', 'host_picture_url'], inplace=True)\n",
    "cal.drop(columns=['adjusted_price'], inplace=True)\n",
    "rev.drop(columns=['reviewer_name'], inplace=True)\n",
    "\n",
    "\n",
    "def convert_to_boolean(df, columns, true_value='t'):\n",
    "    \"\"\"Convert specified columns from string indicators to boolean\"\"\"\n",
    "    for col in columns:\n",
    "        df[col] = df[col] == true_value\n",
    "    return df\n",
    "\n",
    "boolean_cols = ['instant_bookable', 'host_is_superhost', 'host_has_profile_pic', 'host_identity_verified', 'has_availability']\n",
    "lis = convert_to_boolean(lis, boolean_cols)\n",
    "cal['available'] = cal['available'] == 't'\n",
    "\n",
    "\n",
    "def convert_to_datetime(df, columns):\n",
    "    \"\"\"Convert specified columns to datetime\"\"\"\n",
    "    for col in columns:\n",
    "        df[col] = pd.to_datetime(df[col])\n",
    "    return df\n",
    "\n",
    "datetime_cols_lis = ['calendar_last_scraped', 'first_review', 'last_review', 'last_scraped', 'host_since']\n",
    "lis = convert_to_datetime(lis, datetime_cols_lis)\n",
    "cal['date'] = pd.to_datetime(cal['date'])\n",
    "rev['date'] = pd.to_datetime(rev['date'])\n",
    "\n",
    "\n",
    "def convert_to_type(df, columns, dtype):\n",
    "    \"\"\"Convert specified columns to given dtype\"\"\"\n",
    "    for col in columns:\n",
    "        df[col] = df[col].astype(dtype)\n",
    "    return df\n",
    "\n",
    "string_columns = ['bathrooms_text', 'neighbourhood', 'neighbourhood_cleansed', 'property_type', 'room_type', 'host_location', 'host_about', 'host_neighbourhood', 'listing_url', 'host_response_time', 'source', 'name','description','neighborhood_overview']\n",
    "lis = convert_to_type(lis, string_columns, \"string\")\n",
    "rev['comments'] = rev['comments'].astype(\"string\")\n",
    "\n",
    "\n",
    "percentage_cols = ['host_response_rate', 'host_acceptance_rate']\n",
    "for col in percentage_cols:\n",
    "    lis = lis.rename(columns={col: f\"{col}_pct\"})\n",
    "    lis[f\"{col}_pct\"] = lis[f\"{col}_pct\"].str.rstrip('%').astype('float') / 100\n",
    "\n",
    "# Currency inconsistency adjustment\n",
    "lis['price'] = lis['price'].str.replace(r'[\\$,]', '', regex=True)\n",
    "lis = lis.rename(columns={'price': 'price_DKK'})\n",
    "lis['price_DKK'] = pd.to_numeric(lis['price_DKK'], errors='coerce')\n",
    "\n",
    "cal['price'] = cal['price'].str.replace(r'[\\$,]', '', regex=True)\n",
    "cal = cal.rename(columns={'price': 'price_USD'})\n",
    "cal['price_USD'] = pd.to_numeric(cal['price_USD'], errors='coerce')\n",
    "\n",
    "########## Handling list columns ##########\n",
    "\n",
    "lis['amenities_count'] = lis.amenities.str.strip('[]').str.split(',').str.len()\n",
    "\n",
    "\n",
    "def clean_amenity(text):\n",
    "    \"\"\"Clean individual amenity strings\"\"\"\n",
    "    import re\n",
    "    text = str(text) # Convert to string if not already\n",
    "    text = text.strip().strip('\"\\'').strip('.- ') # Basic cleaning\n",
    "    text = text.encode('ascii', 'ignore').decode('ascii') # Replace unicode escape sequences with their characters\n",
    "    text = re.sub(r'\\s+', ' ', text) # Replace multiple spaces with single space\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text) # Remove special characters, keeping only alphanumeric and spaces\n",
    "    text = text.lower().strip() # Convert to lowercase, strip again, and remove any remaining leading/trailing spaces\n",
    "    return text\n",
    "\n",
    "# Clean and convert amenities to comma-separated string\n",
    "lis['amenities'] = lis['amenities'].str.strip('[]').str.split(',').apply(\n",
    "    lambda x: ','.join(\n",
    "        sorted(  # Sort for consistency\n",
    "            filter(None,  # Remove empty strings\n",
    "                [clean_amenity(item) for item in x]\n",
    "            )\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "lis['amenities'] = lis['amenities'].astype('string') # Convert to string dtype\n",
    "\n",
    "# Count number of verifications per host\n",
    "lis['host_verifications_count'] = lis['host_verifications'].str.strip('[]').str.split(', ').str.len()\n",
    "lis['host_verifications'] = lis['host_verifications'].str.strip('[]').str.replace(\"'\", \"\").str.split(', ')\n",
    "# Create one-hot encoded columns\n",
    "verification_dummies = lis['host_verifications'].str.join('|').str.get_dummies()\n",
    "verification_dummies = verification_dummies.add_prefix('verification_')\n",
    "lis = pd.concat([lis, verification_dummies], axis=1)\n",
    "\n",
    "lis.drop(columns=['host_verifications', 'amenities'], inplace=True)\n",
    "\n",
    "print(\"Listings shape:\", lis.shape)\n",
    "print(\"Calendar shape:\", cal.shape) \n",
    "print(\"Reviews shape:\", rev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save processed datasets\n",
    "lis.to_parquet('data/processed/02_listings.parquet')\n",
    "cal.to_parquet('data/processed/02_calendar.parquet')\n",
    "rev.to_parquet('data/processed/02_reviews.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read to regular df, and maintain original Dtypes\n",
    "lis2 = pd.read_parquet('data/processed/02_listings.parquet')\n",
    "cal2 = pd.read_parquet('data/processed/02_calendar.parquet')\n",
    "rev2 = pd.read_parquet('data/processed/02_reviews.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using PostgreSQL COPY command\n",
    "# COPY table_name TO 'output.csv' WITH (FORMAT CSV, HEADER);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>listing_url</th>\n",
       "      <th>last_scraped</th>\n",
       "      <th>source</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>neighborhood_overview</th>\n",
       "      <th>host_id</th>\n",
       "      <th>host_since</th>\n",
       "      <th>host_location</th>\n",
       "      <th>...</th>\n",
       "      <th>calculated_host_listings_count_entire_homes</th>\n",
       "      <th>calculated_host_listings_count_private_rooms</th>\n",
       "      <th>calculated_host_listings_count_shared_rooms</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>amenities_count</th>\n",
       "      <th>host_verifications_count</th>\n",
       "      <th>verification_email</th>\n",
       "      <th>verification_phone</th>\n",
       "      <th>verification_photographer</th>\n",
       "      <th>verification_work_email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2104</th>\n",
       "      <td>11230367</td>\n",
       "      <td>https://www.airbnb.com/rooms/11230367</td>\n",
       "      <td>2024-06-29</td>\n",
       "      <td>city scrape</td>\n",
       "      <td>Five star interior design house.</td>\n",
       "      <td>This 300 sqm high end design house offers excl...</td>\n",
       "      <td>Dahussøen (a large lake) is basically in the b...</td>\n",
       "      <td>58538963</td>\n",
       "      <td>2016-02-13</td>\n",
       "      <td>Copenhagen, Denmark</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2648</th>\n",
       "      <td>14275808</td>\n",
       "      <td>https://www.airbnb.com/rooms/14275808</td>\n",
       "      <td>2024-06-30</td>\n",
       "      <td>city scrape</td>\n",
       "      <td>Two story design home in the ❤️ cph</td>\n",
       "      <td>Two story, Cosy design apartment. (130 kvm). t...</td>\n",
       "      <td>You are inthe middel of Copenhagen, everything...</td>\n",
       "      <td>35863688</td>\n",
       "      <td>2015-06-15</td>\n",
       "      <td>Copenhagen, Denmark</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>23</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5509</th>\n",
       "      <td>33108071</td>\n",
       "      <td>https://www.airbnb.com/rooms/33108071</td>\n",
       "      <td>2024-06-29</td>\n",
       "      <td>city scrape</td>\n",
       "      <td>not available for bookings due to sale</td>\n",
       "      <td>not for bookings due to sale</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>44675877</td>\n",
       "      <td>2015-09-20</td>\n",
       "      <td>Frigiliana, Spain</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7361</th>\n",
       "      <td>44226456</td>\n",
       "      <td>https://www.airbnb.com/rooms/44226456</td>\n",
       "      <td>2024-06-30</td>\n",
       "      <td>city scrape</td>\n",
       "      <td>Grøn landsbyidyl i hjertet af København</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>70535897</td>\n",
       "      <td>2016-05-05</td>\n",
       "      <td>Copenhagen, Denmark</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13336</th>\n",
       "      <td>855445122640003908</td>\n",
       "      <td>https://www.airbnb.com/rooms/855445122640003908</td>\n",
       "      <td>2024-06-30</td>\n",
       "      <td>city scrape</td>\n",
       "      <td>Big apartment in the city center</td>\n",
       "      <td>Enjoy a stylish experience in this centrally l...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>37265782</td>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>Copenhagen, Denmark</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.60</td>\n",
       "      <td>25</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15986</th>\n",
       "      <td>957214416049918750</td>\n",
       "      <td>https://www.airbnb.com/rooms/957214416049918750</td>\n",
       "      <td>2024-06-29</td>\n",
       "      <td>city scrape</td>\n",
       "      <td>skideskuret</td>\n",
       "      <td>You'll remember your time at this romantic and...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>531624660</td>\n",
       "      <td>2023-08-13</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id                                      listing_url  \\\n",
       "2104             11230367            https://www.airbnb.com/rooms/11230367   \n",
       "2648             14275808            https://www.airbnb.com/rooms/14275808   \n",
       "5509             33108071            https://www.airbnb.com/rooms/33108071   \n",
       "7361             44226456            https://www.airbnb.com/rooms/44226456   \n",
       "13336  855445122640003908  https://www.airbnb.com/rooms/855445122640003908   \n",
       "15986  957214416049918750  https://www.airbnb.com/rooms/957214416049918750   \n",
       "\n",
       "      last_scraped       source                                     name  \\\n",
       "2104    2024-06-29  city scrape         Five star interior design house.   \n",
       "2648    2024-06-30  city scrape      Two story design home in the ❤️ cph   \n",
       "5509    2024-06-29  city scrape   not available for bookings due to sale   \n",
       "7361    2024-06-30  city scrape  Grøn landsbyidyl i hjertet af København   \n",
       "13336   2024-06-30  city scrape         Big apartment in the city center   \n",
       "15986   2024-06-29  city scrape                              skideskuret   \n",
       "\n",
       "                                             description  \\\n",
       "2104   This 300 sqm high end design house offers excl...   \n",
       "2648   Two story, Cosy design apartment. (130 kvm). t...   \n",
       "5509                        not for bookings due to sale   \n",
       "7361                                                <NA>   \n",
       "13336  Enjoy a stylish experience in this centrally l...   \n",
       "15986  You'll remember your time at this romantic and...   \n",
       "\n",
       "                                   neighborhood_overview    host_id  \\\n",
       "2104   Dahussøen (a large lake) is basically in the b...   58538963   \n",
       "2648   You are inthe middel of Copenhagen, everything...   35863688   \n",
       "5509                                                <NA>   44675877   \n",
       "7361                                                <NA>   70535897   \n",
       "13336                                               <NA>   37265782   \n",
       "15986                                               <NA>  531624660   \n",
       "\n",
       "      host_since        host_location  ...  \\\n",
       "2104  2016-02-13  Copenhagen, Denmark  ...   \n",
       "2648  2015-06-15  Copenhagen, Denmark  ...   \n",
       "5509  2015-09-20    Frigiliana, Spain  ...   \n",
       "7361  2016-05-05  Copenhagen, Denmark  ...   \n",
       "13336 2015-07-01  Copenhagen, Denmark  ...   \n",
       "15986 2023-08-13                 <NA>  ...   \n",
       "\n",
       "      calculated_host_listings_count_entire_homes  \\\n",
       "2104                                            1   \n",
       "2648                                            1   \n",
       "5509                                            1   \n",
       "7361                                            2   \n",
       "13336                                           1   \n",
       "15986                                           0   \n",
       "\n",
       "      calculated_host_listings_count_private_rooms  \\\n",
       "2104                                             0   \n",
       "2648                                             0   \n",
       "5509                                             0   \n",
       "7361                                             0   \n",
       "13336                                            0   \n",
       "15986                                            1   \n",
       "\n",
       "       calculated_host_listings_count_shared_rooms  reviews_per_month  \\\n",
       "2104                                             0                NaN   \n",
       "2648                                             0               0.63   \n",
       "5509                                             0                NaN   \n",
       "7361                                             0               0.10   \n",
       "13336                                            0               0.60   \n",
       "15986                                            0                NaN   \n",
       "\n",
       "       amenities_count host_verifications_count  verification_email  \\\n",
       "2104                12                      2.0                   1   \n",
       "2648                23                      2.0                   1   \n",
       "5509                11                      2.0                   1   \n",
       "7361                 7                      2.0                   1   \n",
       "13336               25                      2.0                   1   \n",
       "15986               10                      1.0                   0   \n",
       "\n",
       "       verification_phone  verification_photographer  verification_work_email  \n",
       "2104                    1                          0                        0  \n",
       "2648                    1                          0                        0  \n",
       "5509                    1                          0                        0  \n",
       "7361                    1                          0                        0  \n",
       "13336                   1                          0                        0  \n",
       "15986                   1                          0                        0  \n",
       "\n",
       "[6 rows x 70 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lis_df[lis_df['price_DKK'].isin(lis_df['price_DKK'].nlargest(5))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13336    100000.0\n",
       "5509      62000.0\n",
       "7361      41800.0\n",
       "15986     39899.0\n",
       "2104      20000.0\n",
       "Name: price_DKK, dtype: float64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lis_df['price_DKK'].nlargest(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int64             25\n",
       "float64           21\n",
       "string[python]    14\n",
       "datetime64[ns]     5\n",
       "bool               5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lis.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'host_verifications'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/7v/x8q2n09s4d3fr9m02nng047h0000gn/T/ipykernel_34531/836059819.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhost_verifications\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6295\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6296\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6297\u001b[0m         ):\n\u001b[1;32m   6298\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6299\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'host_verifications'"
     ]
    }
   ],
   "source": [
    "lis.host_verifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis[lis.columns[-10:]]#.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis[lis.columns[-20:]].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis.iloc[:10, 40:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis[lis.columns[10:20]].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis[lis.columns[10:20]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert parquet to CSV\n",
    "pd.read_parquet('data/processed/03_calendar.parquet').to_csv('data/processed/03_calendar.csv', index=False)\n",
    "pd.read_parquet('data/processed/03_listings.parquet').to_csv('data/processed/03_listings.csv', index=False)\n",
    "pd.read_parquet('data/processed/03_reviews.parquet').to_csv('data/processed/03_reviews.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>verification_email</th>\n",
       "      <th>verification_phone</th>\n",
       "      <th>verification_photographer</th>\n",
       "      <th>verification_work_email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20904</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20905</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20906</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20907</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20908</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20905 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       verification_email  verification_phone  verification_photographer  \\\n",
       "0                       1                   1                          0   \n",
       "1                       1                   1                          0   \n",
       "2                       1                   1                          0   \n",
       "3                       1                   1                          0   \n",
       "4                       1                   1                          0   \n",
       "...                   ...                 ...                        ...   \n",
       "20904                   0                   1                          0   \n",
       "20905                   1                   1                          0   \n",
       "20906                   1                   1                          0   \n",
       "20907                   1                   1                          0   \n",
       "20908                   1                   1                          0   \n",
       "\n",
       "       verification_work_email  \n",
       "0                            0  \n",
       "1                            0  \n",
       "2                            0  \n",
       "3                            0  \n",
       "4                            1  \n",
       "...                        ...  \n",
       "20904                        0  \n",
       "20905                        0  \n",
       "20906                        0  \n",
       "20907                        0  \n",
       "20908                        0  \n",
       "\n",
       "[20905 rows x 4 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet('data/processed/03_listings.parquet')\n",
    "verification_cols = [col for col in df.columns if col.startswith('verification_')]\n",
    "df[verification_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available verification methods: email, phone, photographer, work_email\n"
     ]
    }
   ],
   "source": [
    "# Get verification columns and create comma-separated string\n",
    "verification_cols = [col.replace('verification_', '') for col in df.columns if col.startswith('verification_')]\n",
    "print(\"Available verification methods:\", ', '.join(verification_cols))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'host_verification'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'host_verification'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mlis_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhost_verification\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'host_verification'"
     ]
    }
   ],
   "source": [
    "lis_df['host_verifications']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amenity analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define key amenity categories that are most relevant for pricing/booking\n",
    "IMPORTANT_AMENITIES = {\n",
    "    'essentials': ['Wifi', 'Kitchen', 'Heating', 'Air conditioning', 'Washer'],\n",
    "    'luxury': ['Pool', 'Hot tub', 'Gym', 'Free parking'],\n",
    "    'safety': ['Smoke alarm', 'Carbon monoxide alarm', 'Fire extinguisher']\n",
    "}\n",
    "\n",
    "# Create binary columns for important amenities and category counts\n",
    "for category, items in IMPORTANT_AMENITIES.items():\n",
    "    # Create binary columns for each important amenity\n",
    "    for item in items:\n",
    "        lis[f'has_{item.lower().replace(\" \", \"_\")}'] = lis['amenities'].str.contains(item, case=False)\n",
    "    \n",
    "    # Create count for each category\n",
    "    lis[f'{category}_count'] = lis['amenities'].apply(\n",
    "        lambda x: sum(item.lower() in x.lower() for item in items)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save processed datasets\n",
    "lis.to_parquet('data/processed/02_listings.parquet')\n",
    "cal.to_parquet('data/processed/02_calendar.parquet')\n",
    "rev.to_parquet('data/processed/02_reviews.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read to regular df, and maintain original Dtypes\n",
    "lis2 = pd.read_parquet('data/processed/02_listings.parquet')\n",
    "cal2 = pd.read_parquet('data/processed/02_calendar.parquet')\n",
    "rev2 = pd.read_parquet('data/processed/02_reviews.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis['amenities']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all unique amenities\n",
    "all_amenities = set()\n",
    "# lis['amenities'].str.split(',').apply(lambda x: [all_amenities.add(item.strip()) for item in x])\n",
    "lis['amenities'].str.strip('[]').str.split(',').apply(lambda x: [all_amenities.add(item.strip()) for item in x])\n",
    "\n",
    "# Sort and print the unique amenities to review\n",
    "sorted_amenities = sorted(all_amenities)\n",
    "\n",
    "print(f\"Total unique amenities: {len(sorted_amenities)}\")\n",
    "print(\"\\nAll unique amenities:\")\n",
    "for amenity in sorted_amenities:\n",
    "    print(f\"- {amenity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all unique amenities\n",
    "all_amenities = set()\n",
    "\n",
    "# Clean the string representation and split\n",
    "lis['amenities'].str.strip('[]').str.split(',').apply(\n",
    "    lambda x: [all_amenities.add(\n",
    "        # Clean each amenity string:\n",
    "        item.strip().strip('\"\\'').strip('.- ').lower()  # Remove quotes, dashes, dots, and extra spaces\n",
    "    ) for item in x]\n",
    ")\n",
    "\n",
    "# Sort and print the unique amenities to review\n",
    "sorted_amenities = sorted(all_amenities)\n",
    "print(f\"Total unique amenities: {len(sorted_amenities)}\")\n",
    "print(\"\\nAll unique amenities:\")\n",
    "for amenity in sorted_amenities:\n",
    "    print(f\"- {amenity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lis['amenities'].str.strip('[]').str.split(',').apply(\n",
    "#     lambda x: [all_amenities.add(\n",
    "#         # Clean each amenity string:\n",
    "#         item.strip().strip('\"\\'').strip('.- ').lower()  # Remove quotes, dashes, dots, and extra spaces\n",
    "#     ) for item in x])\n",
    "\n",
    "def clean_amenity(text):\n",
    "    \"\"\"Clean individual amenity strings\"\"\"\n",
    "    import re\n",
    "    text = str(text) # Convert to string if not already\n",
    "    text = text.strip().strip('\"\\'').strip('.- ') # Basic cleaning\n",
    "    text = text.encode('ascii', 'ignore').decode('ascii') # Replace unicode escape sequences with their characters\n",
    "    text = re.sub(r'\\s+', ' ', text) # Replace multiple spaces with single space\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text) # Remove special characters, keeping only alphanumeric and spaces\n",
    "    text = text.lower().strip() # Convert to lowercase, strip again, and remove any remaining leading/trailing spaces\n",
    "    return text\n",
    "\n",
    "# Clean and convert amenities to comma-separated string\n",
    "lis['amenities'] = lis['amenities'].str.strip('[]').str.split(',').apply(\n",
    "    lambda x: ','.join(\n",
    "        sorted(  # Sort for consistency\n",
    "            filter(None,  # Remove empty strings\n",
    "                [clean_amenity(item) for item in x]\n",
    "            )\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "lis['amenities'] = lis['amenities'].astype('string') # Convert to string dtype\n",
    "\n",
    "# Get all unique amenities for sanity check\n",
    "all_amenities = set()\n",
    "lis['amenities'].str.strip('[]').str.split(',').apply(\n",
    "    lambda x: [all_amenities.add(clean_amenity(item)) for item in x if clean_amenity(item)]\n",
    ")\n",
    "all_amenities.discard('') # Remove empty strings if any made it through\n",
    "\n",
    "# Sort and print the unique amenities to review\n",
    "sorted_amenities = sorted(all_amenities)\n",
    "print(f\"Total unique amenities: {len(sorted_amenities)}\")\n",
    "print(\"\\nAll unique amenities:\")\n",
    "for amenity in sorted_amenities:\n",
    "    print(f\"- {amenity}\")\n",
    "\n",
    "# # Clean and convert amenities to comma-separated string\n",
    "# lis['amenities'] = lis['amenities'].str.strip('[]').str.split(',').apply(\n",
    "#     lambda x: ','.join(\n",
    "#         sorted(  # Sort for consistency\n",
    "#             filter(None, # Remove empty strings\n",
    "#                 [clean_amenity(item) for item in x]\n",
    "#             )\n",
    "#         )\n",
    "#     )\n",
    "# )\n",
    "\n",
    "\n",
    "# # Display a few examples of the cleaned amenities\n",
    "# print(\"Sample of cleaned amenities:\")\n",
    "# print(lis['amenities'][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis['amenities']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_amenities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lis.amenities.str.strip('[]').str.split(',').str.len().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cal.price.unique())#.nunique())\n",
    "lis.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking currency inconsistency in cal and lis csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal.loc[cal['listing_id'] == 262961]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis.loc[lis['id'] == 7631726, ['id', 'price_DKK']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis[['id','listing_url', 'price_DKK']][:2]\n",
    "# calendar_df[calendar_df['listing_id'] == 31094]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis = lis.where(pd.notnull(lis), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "# print(\"Calendar date range:\", cal['datetime'].min(), \"to\", cal['datetime'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get columns with less than 3 unique values\n",
    "low_unique_cols = [col for col in lis.columns if lis[col].nunique() < 3]\n",
    "print(\"Columns with less than 3 unique values:\")\n",
    "for col in low_unique_cols:\n",
    "    print(f\"{col}: {lis[col].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(rev.reviewer_name)#.nunique())\n",
    "rev.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01_init_EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis_df = pd.read_parquet('data/processed/02_listings.parquet')\n",
    "cal_df = pd.read_parquet('data/processed/02_calendar.parquet')\n",
    "rev_df = pd.read_parquet('data/processed/02_reviews.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Initial Data Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data Structure Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_dataset(df, name):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Dataset: {name}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    print(\"\\n1. Basic Information:\")\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    \n",
    "    print(\"\\n2. Data Types:\")\n",
    "    print(df.dtypes)\n",
    "\n",
    "    print(\"\\n3. Summary Statistics:\")\n",
    "    print(df.describe())\n",
    "    \n",
    "    print(\"\\n4. Unique Values:\")\n",
    "    for col in df.columns:\n",
    "        n_unique = df[col].nunique()\n",
    "        if n_unique < 3:\n",
    "            unique_values = df[col].unique()\n",
    "            print(f\"{col}: {n_unique} unique values\")\n",
    "            print(f\"Values: {unique_values}\\n\")\n",
    "\n",
    "    print(\"\\n5. Missing Values:\")\n",
    "    # Todo: Elias ad unique values + here\n",
    "    missing = df.isnull().sum()\n",
    "    missing_pct = (missing / len(df)) * 100\n",
    "    missing_info = pd.DataFrame({\n",
    "        'Missing Values': missing,\n",
    "        'Percentage': missing_pct\n",
    "    })\n",
    "    print(missing_info[missing_info['Missing Values'] > 0])\n",
    "    \n",
    "    return missing_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_missing = explore_dataset(lis_df, 'Listings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar_missing = explore_dataset(cal_df, 'Calendar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_missing = explore_dataset(rev_df, 'Reviews')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Missing Values Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_missing_values(missing_info, title):\n",
    "    # Filter columns with more than 0.1% missing values\n",
    "    missing_filtered = missing_info[missing_info['Percentage'] > 0.001]\n",
    "    \n",
    "    plt.figure(figsize=(18, 10))\n",
    "    ax = missing_filtered['Percentage'].plot(kind='bar')\n",
    "    plt.title(f'Missing Values in {title} Dataset')\n",
    "    plt.xlabel('Columns')\n",
    "    plt.ylabel('Percentage Missing')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    \n",
    "    \n",
    "    # Add total missing values labels on top of each bar, rotated 45 degrees\n",
    "    for i, v in enumerate(missing_filtered['Missing Values']):\n",
    "        ax.text(i, missing_filtered['Percentage'].iloc[i], f'{int(v):,}', \n",
    "                ha='left', va='bottom', fontsize=8, rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot missing values for each dataset\n",
    "plot_missing_values(listings_missing, 'Listings')\n",
    "# plot_missing_values(calendar_missing, 'Calendar')\n",
    "# plot_missing_values(reviews_missing, 'Reviews')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Data Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_data_quality_issues(df, name):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Data Quality Report for {name}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # 1. Check for duplicates\n",
    "    n_duplicates = df.duplicated().sum()\n",
    "    if n_duplicates > 0:\n",
    "        print(f\"\\nDuplicate rows: {n_duplicates}\")\n",
    "    \n",
    "    # 2. Check for unexpected values\n",
    "    numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "    has_unexpected = False\n",
    "    for col in numeric_cols:\n",
    "        n_zeros = (df[col] == 0).sum()\n",
    "        n_negative = (df[col] < 0).sum()\n",
    "        if n_zeros > 0 or n_negative > 0:\n",
    "            if not has_unexpected:\n",
    "                print(\"\\nColumns with unexpected values:\")\n",
    "                has_unexpected = True\n",
    "            print(f\"\\n{col}:\")\n",
    "            if n_zeros > 0:\n",
    "                print(f\"- Zeros: {n_zeros} ({(n_zeros/len(df))*100:.2f}%)\")\n",
    "            if n_negative > 0:\n",
    "                print(f\"- Negative values: {n_negative} ({(n_negative/len(df))*100:.2f}%)\")\n",
    "    \n",
    "    # 3. Check string columns for data inconsistencies\n",
    "    string_cols = df.select_dtypes(include=['object']).columns\n",
    "    has_inconsistencies = False\n",
    "    for col in string_cols:\n",
    "        n_empty = (df[col] == '').sum()\n",
    "        n_whitespace = df[col].str.isspace().sum() if df[col].dtype == 'object' else 0\n",
    "        if n_empty > 0 or n_whitespace > 0:\n",
    "            if not has_inconsistencies:\n",
    "                print(\"\\nColumns with inconsistencies:\")\n",
    "                has_inconsistencies = True\n",
    "            print(f\"\\n{col}:\")\n",
    "            if n_empty > 0:\n",
    "                print(f\"- Empty strings: {n_empty}\")\n",
    "            if n_whitespace > 0:\n",
    "                print(f\"- Whitespace only: {n_whitespace}\")\n",
    "    \n",
    "    # 4. Check for extreme values in numeric columns\n",
    "    has_outliers = False\n",
    "    for col in numeric_cols:\n",
    "        mean = df[col].mean()\n",
    "        std = df[col].std()\n",
    "        outliers = df[col][abs(df[col] - mean) > 3*std]\n",
    "        if len(outliers) > 0:\n",
    "            if not has_outliers:\n",
    "                print(\"\\nColumns with outliers (beyond 3 std devs):\")\n",
    "                has_outliers = True\n",
    "            print(f\"\\n{col}:\")\n",
    "            print(f\"- Number of outliers: {len(outliers)}\")\n",
    "            print(f\"- Min outlier: {outliers.min()}\")\n",
    "            print(f\"- Max outlier: {outliers.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Listings dataset\n",
    "identify_data_quality_issues(lis_df, 'Listings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Calendar dataset\n",
    "identify_data_quality_issues(cal_df, 'Calendar')\n",
    "\n",
    "# Additional calendar-specific checks\n",
    "print(\"\\nChecking calendar date patterns:\")\n",
    "cal_df['date'] = pd.to_datetime(cal_df['date'])\n",
    "print(f\"Date range: {cal_df['date'].min()} to {cal_df['date'].max()}\")\n",
    "print(f\"Missing dates: {cal_df['date'].isnull().sum()}\")\n",
    "print(f\"Days between min and max date: {(cal_df['date'].max() - cal_df['date'].min()).days}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Reviews dataset\n",
    "print(identify_data_quality_issues(rev_df, 'Reviews'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Data Format Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_data_formats(df):\n",
    "    \"\"\"Check for inconsistent formats within columns\"\"\"\n",
    "    for col in df.columns:\n",
    "        # Get sample of unique values\n",
    "        unique_samples = df[col].dropna().unique()[:2]\n",
    "        print(f\"\\n{col}:\")\n",
    "        for sample in unique_samples:\n",
    "            print(f\"Value: {sample}, Type: {type(sample)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_data_formats(lis_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_data_formats(cal_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_data_formats(rev_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Special Characters Examination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_special_characters(df):\n",
    "    \"\"\"Check for special characters that might need handling\"\"\"\n",
    "    string_cols = df.select_dtypes(include=['object']).columns\n",
    "    for col in string_cols:\n",
    "        # Fixed: Properly chain the .any() method\n",
    "        if df[col].astype(str).str.contains(r'[^a-zA-Z0-9\\s\\-.,:/+&æøåÆØÅ]').any():\n",
    "            print(f\"\\n{col} contains special characters\")\n",
    "            # Show examples of rows containing special characters\n",
    "            print(df[df[col].astype(str).str.contains(r'[^a-zA-Z0-9\\s\\-.,:/+&æøåÆØÅ]')][col].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_special_characters(lis_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_special_characters(cal_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_special_characters(rev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
