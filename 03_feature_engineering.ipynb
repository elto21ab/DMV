{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis_df = pd.read_parquet('data/processed/02_listings.parquet')\n",
    "rev_df = pd.read_parquet('data/processed/02_reviews.parquet')\n",
    "print(lis_df.shape,'\\n',rev_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store original columns\n",
    "original_columns = lis_df.columns.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing Quality Indicators\n",
    "# lis_df['is_superhost'] = lis_df['host_is_superhost']  # Already boolean\n",
    "#lis_df['total_reviews'] = lis_df['number_of_reviews'] #TODO\n",
    "# lis_df['avg_rating'] = lis_df['review_scores_rating'] #TODO \n",
    "# lis_df['review_frequency'] = lis_df['reviews_per_month']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location Features\n",
    "COPENHAGEN_CENTER_LAT = 55.6761\n",
    "COPENHAGEN_CENTER_LON = 12.5683\n",
    "\n",
    "# Distance to center in birdeye view\n",
    "lis_df['distance_to_center_km'] = np.sqrt(\n",
    "    (lis_df['latitude'] - COPENHAGEN_CENTER_LAT)**2 + \n",
    "    (lis_df['longitude'] - COPENHAGEN_CENTER_LON)**2\n",
    ") * 111  # Rough conversion to kilometers\n",
    "\n",
    "# Neighborhood density\n",
    "lis_df['listings_in_neighborhood'] = lis_df.groupby('neighbourhood_cleansed')['id'].transform('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price Features\n",
    "# Neighborhood price comparison\n",
    "lis_df['neighborhood_avg_price'] = lis_df.groupby('neighbourhood_cleansed')['price_DKK'].transform('mean')\n",
    "lis_df['price_vs_neighborhood'] = lis_df['price_DKK'] / lis_df['neighborhood_avg_price']\n",
    "\n",
    "# Room type price comparison\n",
    "lis_df['room_type_avg_price'] = lis_df.groupby('room_type')['price_DKK'].transform('mean')\n",
    "lis_df['price_vs_room_type'] = lis_df['price_DKK'] / lis_df['room_type_avg_price']\n",
    "\n",
    "# Value indicators\n",
    "lis_df['price_per_person'] = lis_df['price_DKK'] / lis_df['accommodates']\n",
    "lis_df['price_per_bedroom'] = lis_df['price_DKK'].div(lis_df['bedrooms'].where(lis_df['bedrooms'] > 0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Host"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create boolean masks for different conditions\n",
    "mask_diff_dates = lis_df['first_review'] != lis_df['last_review']\n",
    "mask_same_dates = lis_df['first_review'] == lis_df['last_review']\n",
    "\n",
    "# Initialize host_experience_years with zeros\n",
    "# lis_df['host_experience_years'] = 0\n",
    "\n",
    "# Calculate for different first and last review dates\n",
    "lis_df.loc[mask_diff_dates, 'host_experience_years'] = (\n",
    "    (lis_df.loc[mask_diff_dates, 'last_review'] - \n",
    "     lis_df.loc[mask_diff_dates, 'first_review']).dt.total_seconds() / (365.25 * 24 * 60 * 60)\n",
    ")\n",
    "\n",
    "# Calculate for same first and last review date\n",
    "lis_df.loc[mask_same_dates, 'host_experience_years'] = (\n",
    "    (pd.Timestamp.now() - lis_df.loc[mask_same_dates, 'last_review']).dt.total_seconds() / (365.25 * 24 * 60 * 60)\n",
    ")\n",
    "\n",
    "# Set host_experience_years to 0 where both review dates are missing\n",
    "mask_no_reviews = lis_df['last_review'].isna() & lis_df['first_review'].isna()\n",
    "lis_df.loc[mask_no_reviews, 'host_experience_years'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Response Quality: encode ordinal rating of each possible response time category\n",
    "# lis_df['host_response_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How big of a scale does the host operate on relatively to the rest in this neighborhood\n",
    "lis_df['host_listings_ratio'] = lis_df['host_total_listings_count'] / lis_df['listings_in_neighborhood']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avoid division by zero in yearly_review calculation\n",
    "lis_df['yearly_review'] = lis_df['number_of_reviews'] / lis_df['host_experience_years'].replace(0, 1)\n",
    "lis_df['yearly_review'] = lis_df['yearly_review'].fillna(0)  # No reviews = 0 reviews per year\n",
    "\n",
    "# Calculate review score variance; consistency of the host's recieved reviews by guests\n",
    "review_score_cols = [col for col in lis_df.columns if col.startswith('review_scores_')]\n",
    "lis_df['review_score_variance'] = lis_df[review_score_cols].var(axis=1)\n",
    "lis_df.drop(columns=[col for col in lis_df.columns if 'review_scores_' in col], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print summary of new features\n",
    "print(\"\\nNew Feature Summary:\")\n",
    "new_features = lis_df.columns.difference(original_columns)\n",
    "for col in new_features:\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(lis_df[col].describe())\n",
    "\n",
    "# Check for any issues in new features\n",
    "print(\"\\nChecking for issues in new features:\")\n",
    "print(lis_df[new_features].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop first|last review date, and latitude|longitude after calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis_df.drop(['first_review', 'last_review'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xx. Sentiment Score Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries for language detection and sentiment analysis\n",
    "from langdetect import detect\n",
    "from langdetect.lang_detect_exception import LangDetectException\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "# Function to safely detect language\n",
    "def detect_language(text):\n",
    "    try:\n",
    "        if pd.isna(text) or len(str(text).strip()) < 3:  # Check for very short texts\n",
    "            return 'unknown'\n",
    "        return detect(str(text))\n",
    "    except LangDetectException:\n",
    "        return 'unknown'\n",
    "    except Exception as e:\n",
    "        print(f\"Error detecting language: {str(e)}\")\n",
    "        return 'unknown'\n",
    "\n",
    "# Initialize the multilingual sentiment analyzer\n",
    "sentiment_analyzer = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=\"nlptown/bert-base-multilingual-uncased-sentiment\",\n",
    "    device=0 if torch.cuda.is_available() else -1\n",
    ")\n",
    "\n",
    "# Function to get sentiment score (-1 to 1 range)\n",
    "def get_multilingual_sentiment(text):\n",
    "    try:\n",
    "        if pd.isna(text) or len(str(text).strip()) < 3:\n",
    "            return 0\n",
    "        \n",
    "        # Get sentiment (returns 1-5 score)\n",
    "        result = sentiment_analyzer(text[:512])[0]  # Truncate to 512 tokens max\n",
    "        score = int(result['label'][0])  # Extract 1-5 score\n",
    "        \n",
    "        # Convert 1-5 score to -1 to 1 range\n",
    "        normalized_score = (score - 3) / 2  # Convert 1-5 to -1 to 1\n",
    "        \n",
    "        return normalized_score\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing text: {str(e)}\")\n",
    "        return 0\n",
    "\n",
    "# Calculate sentiment scores and detect language\n",
    "print(\"Calculating sentiment scores and detecting languages...\")\n",
    "rev_df['detected_language'] = rev_df['comments'].apply(detect_language)\n",
    "\n",
    "# Process reviews in batches to show progress\n",
    "batch_size = 100\n",
    "total_batches = len(rev_df) // batch_size + 1\n",
    "\n",
    "for i in range(total_batches):\n",
    "    start_idx = i * batch_size\n",
    "    end_idx = min((i + 1) * batch_size, len(rev_df))\n",
    "    \n",
    "    print(f\"Processing batch {i+1}/{total_batches}\")\n",
    "    \n",
    "    rev_df.loc[start_idx:end_idx, 'sentiment_score'] = rev_df.loc[start_idx:end_idx, 'comments'].apply(\n",
    "        get_multilingual_sentiment\n",
    "    )\n",
    "\n",
    "# Print language distribution\n",
    "print(\"\\nLanguage Distribution:\")\n",
    "print(rev_df['detected_language'].value_counts())\n",
    "\n",
    "# Sample reviews in different languages with their sentiment scores\n",
    "for lang in rev_df['detected_language'].value_counts().head().index:\n",
    "    if lang != 'unknown':  # Skip unknown language samples\n",
    "        print(f\"\\nSample {lang} reviews:\")\n",
    "        print(\"-\" * 80)\n",
    "        sample = rev_df[rev_df['detected_language'] == lang].sample(2)\n",
    "        print(sample[['comments', 'sentiment_score', 'detected_language']].to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xx. Final Status Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Listings shape:\", lis_df.shape)\n",
    "print(\"Reviews shape:\", rev_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xx. Save Processed Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis_df.to_parquet('data/processed/03_listings.parquet')\n",
    "rev_df.to_parquet('data/processed/03_reviews.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
