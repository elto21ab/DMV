{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setup and Processed Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis_df = pd.read_parquet('data/processed/02_listings.parquet')\n",
    "rev_df = pd.read_parquet('data/processed/02_reviews.parquet')\n",
    "print(lis_df.shape,'\\n',rev_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Feature Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store original columns\n",
    "original_columns = lis_df.columns.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location Features\n",
    "COPENHAGEN_CENTER_LAT = 55.6761\n",
    "COPENHAGEN_CENTER_LON = 12.5683\n",
    "\n",
    "# Distance to center in birdeye view\n",
    "lis_df['distance_to_center_km'] = np.sqrt(\n",
    "    (lis_df['latitude'] - COPENHAGEN_CENTER_LAT)**2 + \n",
    "    (lis_df['longitude'] - COPENHAGEN_CENTER_LON)**2\n",
    ") * 111  # Rough conversion to kilometers\n",
    "\n",
    "# Neighborhood density\n",
    "lis_df['listings_in_neighborhood'] = lis_df.groupby('neighbourhood_cleansed')['id'].transform('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price Features\n",
    "# Neighborhood price comparison\n",
    "lis_df['neighborhood_avg_price'] = lis_df.groupby('neighbourhood_cleansed')['price_DKK'].transform('mean')\n",
    "lis_df['price_vs_neighborhood'] = lis_df['price_DKK'] / lis_df['neighborhood_avg_price']\n",
    "\n",
    "# Room type price comparison\n",
    "lis_df['room_type_avg_price'] = lis_df.groupby('room_type')['price_DKK'].transform('mean')\n",
    "lis_df['price_vs_room_type'] = lis_df['price_DKK'] / lis_df['room_type_avg_price']\n",
    "\n",
    "# Value indicators\n",
    "lis_df['price_per_person'] = lis_df['price_DKK'] / lis_df['accommodates']\n",
    "lis_df['price_per_bedroom'] = lis_df['price_DKK'].div(lis_df['bedrooms'].where(lis_df['bedrooms'] > 0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create boolean masks for different conditions\n",
    "mask_diff_dates = lis_df['first_review'] != lis_df['last_review']\n",
    "mask_same_dates = lis_df['first_review'] == lis_df['last_review']\n",
    "\n",
    "\n",
    "# Calculate for different first and last review dates\n",
    "lis_df.loc[mask_diff_dates, 'host_experience_years'] = (\n",
    "    (lis_df.loc[mask_diff_dates, 'last_review'] - \n",
    "     lis_df.loc[mask_diff_dates, 'first_review']).dt.total_seconds() / (365.25 * 24 * 60 * 60)\n",
    ")\n",
    "\n",
    "# Calculate for same first and last review date\n",
    "lis_df.loc[mask_same_dates, 'host_experience_years'] = (\n",
    "    (pd.Timestamp.now() - lis_df.loc[mask_same_dates, 'last_review']).dt.total_seconds() / (365.25 * 24 * 60 * 60)\n",
    ")\n",
    "\n",
    "# Set host_experience_years to 0 where both review dates are missing\n",
    "mask_no_reviews = lis_df['last_review'].isna() & lis_df['first_review'].isna()\n",
    "lis_df.loc[mask_no_reviews, 'host_experience_years'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How big of a scale does the host operate on relatively to the rest in this neighborhood\n",
    "lis_df['host_listings_ratio'] = lis_df['host_total_listings_count'] / lis_df['listings_in_neighborhood']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avoid division by zero in yearly_review calculation\n",
    "lis_df['yearly_review'] = lis_df['number_of_reviews'] / lis_df['host_experience_years'].replace(0, 1)\n",
    "lis_df['yearly_review'] = lis_df['yearly_review'].fillna(0)  # No reviews = 0 reviews per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print summary of new features\n",
    "print(\"\\nNew Feature Summary:\")\n",
    "new_features = lis_df.columns.difference(original_columns)\n",
    "for col in new_features:\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(lis_df[col].describe())\n",
    "\n",
    "# Check for any issues in new features\n",
    "print(\"\\nChecking for issues in new features:\")\n",
    "print(lis_df[new_features].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop first & last review date, as we've now created the attribute host_experience_years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis_df.drop(['first_review', 'last_review'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Sentiment Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total length of all comments\n",
    "total_comment_length = rev_df['comments'].str.len().sum()\n",
    "print(f\"Total length of all comments: {total_comment_length:,} characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Initialize model and tokenizer\n",
    "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"  \n",
    "sentiment_analyzer = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=model_name,\n",
    "    tokenizer=model_name,\n",
    "    device=0 if torch.cuda.is_available() else -1\n",
    ")\n",
    "\n",
    "def get_sentiment_score(text):\n",
    "    if pd.isna(text) or len(str(text).strip()) < 3:\n",
    "        return 0\n",
    "    try:\n",
    "        # Truncate long texts to 512 tokens\n",
    "        result = sentiment_analyzer(str(text)[:10000])[0]\n",
    "        \n",
    "        # This model returns scores from 1-5 stars\n",
    "        score = int(result['label'][0])  # Get first character (1-5)\n",
    "        \n",
    "        # Convert 1-5 scale to [-1, 1]\n",
    "        normalized_score = (score - 3) / 2\n",
    "        \n",
    "        # Weight by confidence\n",
    "        final_score = normalized_score * result['score']\n",
    "        \n",
    "        return final_score\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing text: {str(e)}\")\n",
    "        return 0\n",
    "\n",
    "# Take a sample of 1000 reviews\n",
    "sample_size = 10\n",
    "print(f\"Processing sample of {sample_size} reviews...\")\n",
    "rev_sample = rev_df.sample(sample_size, random_state=42)\n",
    "\n",
    "# Process reviews with progress bar\n",
    "print(\"Calculating sentiment scores...\")\n",
    "rev_sample['sentiment_score'] = [get_sentiment_score(text) for text in tqdm(rev_sample['comments'])]\n",
    "\n",
    "# Show results\n",
    "print(\"\\nSample Results by Sentiment Category:\")\n",
    "for sentiment, range_vals in [\n",
    "    ('Very Positive', (0.5, 1.0)),\n",
    "    ('Positive', (0.1, 0.5)),\n",
    "    ('Neutral', (-0.1, 0.1)),\n",
    "    ('Negative', (-0.5, -0.1)),\n",
    "    ('Very Negative', (-1.0, -0.5))\n",
    "]:\n",
    "    mask = (rev_sample['sentiment_score'] >= range_vals[0]) & (rev_sample['sentiment_score'] <= range_vals[1])\n",
    "    print(f\"\\n{sentiment} Reviews Examples (3 random samples):\")\n",
    "    sample = rev_sample[mask].sample(min(3, len(rev_sample[mask])))\n",
    "    for _, row in sample.iterrows():\n",
    "        print(f\"\\nScore: {row['sentiment_score']:.3f}\")\n",
    "        print(f\"Review: {row['comments'][:20000]}\")\n",
    "\n",
    "# Print distribution statistics\n",
    "print(\"\\nSentiment Score Distribution:\")\n",
    "print(rev_sample['sentiment_score'].describe())\n",
    "\n",
    "# Save results\n",
    "rev_sample.to_parquet('data/processed/04_sentiment_bert.parquet', index=False)\n",
    "rev_sample.to_csv('data/processed/04_sentiment_bert.csv', index=False)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "lis_df = pd.read_parquet('data/processed/03_listings.parquet')\n",
    "rev_s = pd.read_parquet('data/processed/04_sentiment_bert.parquet')\n",
    "rev_s['sentiment_score_1_5'] = (rev_s['sentiment_score'] * 2) + 3\n",
    "rev_s = rev_s.drop('sentiment_score', axis=1)\n",
    "rev_s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis_df.drop(columns=['name','description','host_response_rate_pct','neighbourhood_cleansed',  'has_availability', 'host_since', 'host_has_profile_pic'], inplace=True) \n",
    "\n",
    "lis_df.drop(columns=['price_vs_room_type', 'price_per_person', 'price_per_bedroom', 'neighborhood_avg_price','price_vs_neighborhood','room_type_avg_price', 'host_listings_ratio' ], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Final Status Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Listings shape:\", lis_df.shape)\n",
    "print(\"Reviews shape:\", rev_s.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Save Processed Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis_df.to_parquet('data/processed/05_listings.parquet')\n",
    "rev_s.to_parquet('data/processed/05_sentiment_bert.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
