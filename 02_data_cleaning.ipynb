{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setup and Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_df = pd.read_csv('data/raw/calendar2024.csv')\n",
    "lis_df = pd.read_csv('data/raw/listings2024.csv') \n",
    "rev_df = pd.read_csv('data/raw/reviews2024.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Initial Column Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove empty columns\n",
    "null_cols_lis = lis_df.columns[lis_df.isna().all()].tolist()\n",
    "lis_df = lis_df.drop(columns=null_cols_lis)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "lis_df.drop(columns=['scrape_id', 'host_name', 'picture_url', 'host_url', 'host_thumbnail_url', 'host_picture_url'], inplace=True)\n",
    "cal_df.drop(columns=['adjusted_price'], inplace=True)\n",
    "rev_df.drop(columns=['reviewer_name'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data Type Conversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def convert_to_boolean(df, columns, true_value='t'):\n",
    "    \"\"\"Convert specified columns from string indicators to boolean\"\"\"\n",
    "    for col in columns:\n",
    "        df[col] = df[col] == true_value\n",
    "    return df\n",
    "\n",
    "def convert_to_datetime(df, columns):\n",
    "    \"\"\"Convert specified columns to datetime\"\"\"\n",
    "    for col in columns:\n",
    "        df[col] = pd.to_datetime(df[col])\n",
    "    return df\n",
    "\n",
    "def convert_to_type(df, columns, dtype):\n",
    "    \"\"\"Convert specified columns to given dtype\"\"\"\n",
    "    for col in columns:\n",
    "        df[col] = df[col].astype(dtype)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Apply Type Conversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boolean conversions\n",
    "boolean_cols = ['instant_bookable', 'host_is_superhost', 'host_has_profile_pic', 'host_identity_verified', 'has_availability']\n",
    "lis = convert_to_boolean(lis, boolean_cols)\n",
    "cal_df['available'] = cal_df['available'] == 't'\n",
    "\n",
    "# Datetime conversions\n",
    "datetime_cols_lis = ['calendar_last_scraped', 'first_review', 'last_review', 'last_scraped', 'host_since']\n",
    "lis = convert_to_datetime(lis, datetime_cols_lis)\n",
    "cal_df['date'] = pd.to_datetime(cal_df['date'])\n",
    "rev_df['date'] = pd.to_datetime(rev_df['date'])\n",
    "\n",
    "# String conversions\n",
    "string_columns = ['bathrooms_text', 'neighbourhood', 'neighbourhood_cleansed', 'property_type', 'room_type', 'host_location', 'host_about', 'host_neighbourhood', 'listing_url', 'host_response_time', 'source', 'name', 'description', 'neighborhood_overview']\n",
    "lis_df = convert_to_type(lis_df, string_columns, \"string\")\n",
    "rev_df['comments'] = rev_df['comments'].astype(\"string\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Handle Percentage and Currency Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert percentage columns\n",
    "percentage_cols = ['host_response_rate', 'host_acceptance_rate']\n",
    "for col in percentage_cols:\n",
    "    lis_df = lis_df.rename(columns={col: f\"{col}_pct\"})\n",
    "    lis_df[f\"{col}_pct\"] = lis_df[f\"{col}_pct\"].str.rstrip('%').astype('float') / 100\n",
    "\n",
    "# Clean and standardize price columns\n",
    "#DKK\n",
    "lis_df['price'] = lis_df['price'].str.replace(r'[\\$,]', '', regex=True)\n",
    "lis_df = lis_df.rename(columns={'price': 'price_DKK'})\n",
    "lis_df['price_DKK'] = pd.to_numeric(lis_df['price_DKK'], errors='coerce')\n",
    "\n",
    "#USD\n",
    "cal_df['price'] = cal_df['price'].str.replace(r'[\\$,]', '', regex=True)\n",
    "cal_df = cal_df.rename(columns={'price': 'price_USD'})\n",
    "cal_df['price_USD'] = pd.to_numeric(cal_df['price_USD'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Process array-Type Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process amenities\n",
    "lis_df['amenities_count'] = lis_df.amenities.str.strip('[]').str.split(',').str.len()\n",
    "\n",
    "def clean_amenity(text):\n",
    "    \"\"\"Clean individual amenity strings\"\"\"\n",
    "    import re\n",
    "    text = str(text) # Convert to string if not already\n",
    "    text = text.strip().strip('\"\\'').strip('.- ') # Basic cleaning\n",
    "    text = text.encode('ascii', 'ignore').decode('ascii') # Replace unicode escape sequences with their characters\n",
    "    text = re.sub(r'\\s+', ' ', text) # Replace multiple spaces with single space\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text) # Remove special characters, keeping only alphanumeric and spaces\n",
    "    text = text.lower().strip() # Convert to lowercase, strip again, and remove any remaining leading/trailing spaces\n",
    "    return text\n",
    "\n",
    "# Clean and convert amenities to comma-separated string\n",
    "lis_df['amenities'] = lis_df['amenities'].str.strip('[]').str.split(',').apply(\n",
    "    lambda x: ','.join(\n",
    "        sorted(  # Sort for consistency\n",
    "            filter(None,  # Remove empty strings\n",
    "                [clean_amenity(item) for item in x]\n",
    "            )\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "lis_df['amenities'] = lis_df['amenities'].astype('string') # Convert to string dtype\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Process host verifications\n",
    "# Count number of verifications per host\n",
    "lis_df['host_verifications_count'] = lis_df['host_verifications'].str.strip('[]').str.split(', ').str.len()\n",
    "lis_df['host_verifications'] = lis_df['host_verifications'].str.strip('[]').str.replace(\"'\", \"\").str.split(', ')\n",
    "# Create one-hot encoded columns\n",
    "verification_dummies = lis_df['host_verifications'].str.join('|').str.get_dummies()\n",
    "verification_dummies = verification_dummies.add_prefix('verification_')\n",
    "lis_df = pd.concat([lis_df, verification_dummies], axis=1)\n",
    "\n",
    "lis_df.drop(columns=['host_verifications', 'amenities'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis_df.to_parquet('data/processed/02_listings.parquet')\n",
    "cal_df.to_parquet('data/processed/02_calendar.parquet')\n",
    "rev_df.to_parquet('data/processed/02_reviews.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Handle Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputation for Listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Physical characteristics imputation - revised approach\n",
    "# Bathrooms - keep room_type median as it must exist\n",
    "lis_df['bathrooms'] = lis_df.groupby('room_type')['bathrooms'].transform(lambda x: x.fillna(x.median()))\n",
    "lis_df['bathrooms'] = lis_df['bathrooms'].fillna(1.0)  # Fallback to 1 if still missing\n",
    "\n",
    "# Bedrooms - set to 0 for shared/studio, impute for homes\n",
    "lis_df.loc[lis_df['room_type'].isin(['Shared room', 'Private room']), 'bedrooms'] = \\\n",
    "    lis_df.loc[lis_df['room_type'].isin(['Shared room', 'Private room']), 'bedrooms'].fillna(0)\n",
    "lis_df.loc[lis_df['room_type'] == 'Entire home/apt', 'bedrooms'] = \\\n",
    "    lis_df.loc[lis_df['room_type'] == 'Entire home/apt', 'bedrooms'].transform(lambda x: x.fillna(x.median()))\n",
    "lis_df['bedrooms'] = lis_df['bedrooms'].fillna(0)  # Any remaining missing to 0\n",
    "\n",
    "# Beds - ensure at least 1 bed per listing based on accommodates\n",
    "lis_df['beds'] = lis_df['beds'].fillna(lis_df['accommodates'].clip(lower=1))\n",
    "\n",
    "\n",
    "# Price imputation\n",
    "# If price is missing, use the median price for that room type\n",
    "lis_df['price_DKK'] = lis_df.groupby('room_type')['price_DKK'].transform(lambda x: x.fillna(x.median()))\n",
    "\n",
    "# If any prices are still missing (very rare case), use overall median\n",
    "lis_df['price_DKK'] = lis_df['price_DKK'].fillna(lis_df['price_DKK'].median())\n",
    "\n",
    "\n",
    "\n",
    "# Numeric imputation - ensure all numeric fields have appropriate values for PostgreSQL numeric types\n",
    "numeric_cols_to_impute = {\n",
    "    'host_response_rate_pct': 0.0,  # Use 0 instead of mean for percentage\n",
    "    'host_acceptance_rate_pct': 0.0,  # Use 0 instead of mean for percentage\n",
    "    'review_scores_rating': 0,  # Use 0 instead of median for scores\n",
    "    'review_scores_accuracy': 0,\n",
    "    'review_scores_cleanliness': 0,\n",
    "    'review_scores_checkin': 0,\n",
    "    'review_scores_communication': 0,\n",
    "    'review_scores_location': 0,\n",
    "    'review_scores_value': 0,\n",
    "    'reviews_per_month': 0,\n",
    "    'host_listings_count': 1,\n",
    "    'host_total_listings_count': 1\n",
    "}\n",
    "\n",
    "for col, value in numeric_cols_to_impute.items():\n",
    "    lis[col] = lis[col].fillna(value)\n",
    "\n",
    "# Categorical imputation - use empty string for VARCHAR fields where appropriate\n",
    "categorical_cols_to_impute = {\n",
    "    'host_response_time': '',  # VARCHAR\n",
    "    'host_neighbourhood': '',  # VARCHAR\n",
    "    'bathrooms_text': '',  # VARCHAR\n",
    "    'neighbourhood': 'mode',  # Keep mode for geographic consistency\n",
    "    'neighbourhood_cleansed': 'mode',  # Keep mode for geographic consistency\n",
    "    'host_location': 'Copenhagen, Denmark',  # Important location default\n",
    "    'host_verifications': '[]'  # JSON-compatible empty array\n",
    "}\n",
    "\n",
    "for col, strategy in categorical_cols_to_impute.items():\n",
    "    if strategy == 'mode':\n",
    "        lis_df[col] = lis_df[col].fillna(lis_df[col].mode()[0])\n",
    "    else:\n",
    "        lis_df[col] = lis_df[col].fillna(strategy)\n",
    "\n",
    "# Text columns - use empty string for TEXT fields\n",
    "text_cols_to_impute = ['host_about', 'neighborhood_overview', 'description']\n",
    "for col in text_cols_to_impute:\n",
    "    lis_df[col] = lis_df[col].fillna('')\n",
    "\n",
    "# Date columns - use explicit PostgreSQL-compatible dates\n",
    "current_date = pd.Timestamp.now().date()\n",
    "lis_df['host_since'] = lis_df['host_since'].fillna(pd.Timestamp('2000-01-01'))  # Use explicit default date\n",
    "lis_df['first_review'] = lis_df['first_review'].fillna(pd.NaT)  # Keep as NULL for no reviews\n",
    "lis_df['last_review'] = lis_df['last_review'].fillna(pd.NaT)  # Keep as NULL for no reviews\n",
    "\n",
    "# Boolean columns - ensure True/False (not NULL)\n",
    "boolean_cols = ['instant_bookable', 'host_is_superhost', 'host_has_profile_pic', \n",
    "                'host_identity_verified', 'has_availability']\n",
    "for col in boolean_cols:\n",
    "    lis_df[col] = lis_df[col].fillna(False)  # Default to False for missing booleans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputation for Calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price imputation for calendar\n",
    "cal_df['price_USD'] = cal_df.groupby(['listing_id', 'available'])['price_USD'].transform(lambda x: x.fillna(x.median()))\n",
    "cal_df['price_USD'] = cal_df['price_USD'].fillna(0)  # Default to 0 for any remaining NULL prices\n",
    "\n",
    "# Handle minimum and maximum nights\n",
    "cal_df['minimum_nights'] = cal_df.groupby('listing_id')['minimum_nights'].transform(lambda x: x.fillna(x.median()))\n",
    "cal_df['maximum_nights'] = cal_df.groupby('listing_id')['maximum_nights'].transform(lambda x: x.fillna(x.median()))\n",
    "# Default to 1 and 365 if still missing\n",
    "cal_df['minimum_nights'] = cal_df['minimum_nights'].fillna(1)\n",
    "cal_df['maximum_nights'] = cal_df['maximum_nights'].fillna(365)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputation for Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing comments\n",
    "rev_df['comments'] = rev_df['comments'].fillna('')  # Empty string for TEXT field\n",
    "\n",
    "# Handle missing dates (shouldn't be any, but just in case)\n",
    "rev_df['date'] = rev_df['date'].fillna(pd.Timestamp('2000-01-01'))  # Use explicit default date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After all imputations, check which columns still have nulls\n",
    "null_check = lis_df.isnull().sum()\n",
    "print(\"\\nColumns with remaining NULL values:\")\n",
    "print(null_check[null_check > 0])\n",
    "\n",
    "# Fix remaining nulls based on their data types\n",
    "for col in lis_df.columns[lis_df.isnull().any()]:\n",
    "    dtype = lis_df[col].dtype\n",
    "    \n",
    "    if np.issubdtype(dtype, np.number):  # Numeric columns\n",
    "        lis_df[col] = lis_df[col].fillna(0)\n",
    "    elif dtype == 'datetime64[ns]':  # DateTime columns\n",
    "        lis_df[col] = lis_df[col].fillna(pd.Timestamp('2000-01-01'))\n",
    "    elif dtype == 'bool':  # Boolean columns\n",
    "        lis_df[col] = lis_df[col].fillna(False)\n",
    "    else:  # String/object columns\n",
    "        lis_df[col] = lis_df[col].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify imputation\n",
    "print(\"\\nVerifying no NULL values remain:\")\n",
    "print(\"\\nListings nulls:\", lis_df.isnull().sum().sum())\n",
    "print(\"Calendar nulls:\", cal_df.isnull().sum().sum())\n",
    "print(\"Reviews nulls:\", rev_df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store original columns\n",
    "original_columns = lis_df.columns.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing Quality Indicators\n",
    "lis_df['is_superhost'] = lis_df['host_is_superhost']  # Already boolean\n",
    "lis_df['total_reviews'] = lis_df['number_of_reviews']\n",
    "lis_df['avg_rating'] = lis_df['review_scores_rating']\n",
    "lis_df['review_frequency'] = lis_df['reviews_per_month']\n",
    "\n",
    "# Availability and Demand\n",
    "lis_df['availability_365'] = lis_df['availability_90']  # How often is it available?\n",
    "lis_df['occupancy_rate'] = 1 - (lis_df['availability_365'] / 365)  # Inverse of availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location Features\n",
    "COPENHAGEN_CENTER_LAT = 55.6761\n",
    "COPENHAGEN_CENTER_LON = 12.5683\n",
    "\n",
    "# Distance to center\n",
    "lis_df['distance_to_center_km'] = np.sqrt(\n",
    "    (lis_df['latitude'] - COPENHAGEN_CENTER_LAT)**2 + \n",
    "    (lis_df['longitude'] - COPENHAGEN_CENTER_LON)**2\n",
    ") * 111  # Rough conversion to kilometers\n",
    "\n",
    "# Neighborhood density\n",
    "lis_df['listings_in_neighborhood'] = lis_df.groupby('neighbourhood_cleansed')['id'].transform('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price Features\n",
    "# Neighborhood price comparison\n",
    "lis_df['neighborhood_avg_price'] = lis_df.groupby('neighbourhood_cleansed')['price_DKK'].transform('mean')\n",
    "lis_df['price_vs_neighborhood'] = lis_df['price_DKK'] / lis_df['neighborhood_avg_price']\n",
    "\n",
    "# Room type price comparison\n",
    "lis_df['room_type_avg_price'] = lis_df.groupby('room_type')['price_DKK'].transform('mean')\n",
    "lis_df['price_vs_room_type'] = lis_df['price_DKK'] / lis_df['room_type_avg_price']\n",
    "\n",
    "# Value indicators\n",
    "lis_df['price_per_person'] = lis_df['price_DKK'] / lis_df['accommodates']\n",
    "lis_df['price_per_bedroom'] = lis_df['price_DKK'].div(lis_df['bedrooms'].where(lis_df['bedrooms'] > 0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Host Features\n",
    "lis_df['host_experience_years'] = (pd.Timestamp.now() - lis_df['host_since']).dt.total_seconds() / (365.25 * 24 * 60 * 60)\n",
    "lis_df['host_listings_ratio'] = lis_df['host_total_listings_count'] / lis_df['listings_in_neighborhood']\n",
    "\n",
    "# Response Quality\n",
    "lis_df['host_response_speed'] = pd.Categorical(lis_df['host_response_time'], \n",
    "    categories=['within an hour', 'within a few hours', 'within a day', 'a few days or more'], \n",
    "    ordered=True).codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review Features\n",
    "lis_df['days_since_last_review'] = (pd.Timestamp.now() - lis_df['last_review']).dt.total_seconds() / (24 * 60 * 60)\n",
    "lis_df['review_rate'] = lis_df['number_of_reviews'] / lis_df['host_experience_years']\n",
    "\n",
    "# Calculate review score variance\n",
    "review_score_cols = [col for col in lis_df.columns if col.startswith('review_scores_')]\n",
    "lis_df['review_score_variance'] = lis_df[review_score_cols].var(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calendar Features\n",
    "cal_df['date'] = pd.to_datetime(cal_df['date'])\n",
    "cal_df['is_weekend'] = cal_df['date'].dt.dayofweek >= 5\n",
    "cal_df['is_holiday'] = cal_df['date'].dt.month.isin([6, 7, 8, 12])  # Summer and December\n",
    "\n",
    "# Aggregate to listing level\n",
    "calendar_features = cal_df.groupby('listing_id').agg({\n",
    "    'price_USD': ['mean', 'std'],\n",
    "    'is_weekend': 'mean',  # Proportion of weekend days\n",
    "    'is_holiday': 'mean',  # Proportion of holiday days\n",
    "    'available': 'mean'    # Proportion of available days\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print summary of new features\n",
    "print(\"\\nNew Feature Summary:\")\n",
    "new_features = lis_df.columns.difference(original_columns)\n",
    "for col in new_features:\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(lis_df[col].describe())\n",
    "\n",
    "# Check for any issues in new features\n",
    "print(\"\\nChecking for issues in new features:\")\n",
    "print(lis_df[new_features].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Final Status Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Listings shape:\", lis_df.shape)\n",
    "print(\"Calendar shape:\", cal_df.shape) \n",
    "print(\"Reviews shape:\", rev_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Save Processed Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis_df.to_parquet('data/processed/03_listings_cleaned.parquet')\n",
    "cal_df.to_parquet('data/processed/03_calendar_cleaned.parquet') \n",
    "rev_df.to_parquet('data/processed/03_reviews_cleaned.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
