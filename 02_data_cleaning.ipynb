{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setup and Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_df = pd.read_csv('data/raw/calendar2024.csv')\n",
    "lis_df = pd.read_csv('data/raw/listings2024.csv') \n",
    "rev_df = pd.read_csv('data/raw/reviews2024.csv')\n",
    "print('rev:',rev_df.shape)\n",
    "print('lis:',lis_df.shape)\n",
    "print('cal:',cal_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Initial Column Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove empty columns\n",
    "null_cols_lis = lis_df.columns[lis_df.isna().all()].tolist()\n",
    "lis_df = lis_df.drop(columns=null_cols_lis)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "lis_df.drop(columns=['scrape_id', 'host_name', 'picture_url', 'host_url', 'host_thumbnail_url', 'host_picture_url', 'host_listings_count', 'calculated_host_listings_count', 'calculated_host_listings_count_entire_homes', 'calculated_host_listings_count_private_rooms', 'calculated_host_listings_count_shared_rooms',], inplace=True)\n",
    "\n",
    "# cal_df.drop(columns=['adjusted_price'], inplace=True)\n",
    "rev_df.drop(columns=['reviewer_name'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data Type Conversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def convert_to_boolean(df, columns, true_value='t'):\n",
    "    \"\"\"Convert specified columns from string indicators to boolean\"\"\"\n",
    "    for col in columns:\n",
    "        df[col] = df[col] == true_value\n",
    "    return df\n",
    "\n",
    "def convert_to_datetime(df, columns):\n",
    "    \"\"\"Convert specified columns to datetime\"\"\"\n",
    "    for col in columns:\n",
    "        df[col] = pd.to_datetime(df[col])\n",
    "    return df\n",
    "\n",
    "def convert_to_type(df, columns, dtype):\n",
    "    \"\"\"Convert specified columns to given dtype\"\"\"\n",
    "    for col in columns:\n",
    "        df[col] = df[col].astype(dtype)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Apply Type Conversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boolean conversions\n",
    "boolean_cols = ['instant_bookable', 'host_is_superhost', 'host_has_profile_pic', 'host_identity_verified', 'has_availability']\n",
    "lis_df = convert_to_boolean(lis_df, boolean_cols)\n",
    "# cal_df['available'] = cal_df['available'] == 't'\n",
    "\n",
    "# Datetime conversions\n",
    "datetime_cols_lis = ['calendar_last_scraped', 'first_review', 'last_review', 'last_scraped', 'host_since']\n",
    "lis_df = convert_to_datetime(lis_df, datetime_cols_lis)\n",
    "# cal_df['date'] = pd.to_datetime(cal_df['date'])\n",
    "rev_df['date'] = pd.to_datetime(rev_df['date'])\n",
    "\n",
    "# String conversions\n",
    "string_columns = ['bathrooms_text', 'neighbourhood', 'neighbourhood_cleansed', 'property_type', 'room_type', 'host_location', 'host_about', 'host_neighbourhood', 'listing_url', 'host_response_time', 'source', 'name', 'description', 'neighborhood_overview']\n",
    "lis_df = convert_to_type(lis_df, string_columns, \"string\")\n",
    "rev_df['comments'] = rev_df['comments'].astype(\"string\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Handle Percentage and Currency Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert percentage columns\n",
    "percentage_cols = ['host_response_rate', 'host_acceptance_rate']\n",
    "for col in percentage_cols:\n",
    "    lis_df = lis_df.rename(columns={col: f\"{col}_pct\"})\n",
    "    lis_df[f\"{col}_pct\"] = lis_df[f\"{col}_pct\"].str.rstrip('%').astype('float') / 100\n",
    "\n",
    "# fix price columns\n",
    "#DKK\n",
    "lis_df['price'] = lis_df['price'].str.replace(r'[\\$,]', '', regex=True)\n",
    "lis_df = lis_df.rename(columns={'price': 'price_DKK'})\n",
    "lis_df['price_DKK'] = pd.to_numeric(lis_df['price_DKK'], errors='coerce')\n",
    "\n",
    "# Drop the 4 most expensive listings (they looked like ingenuine outliers)\n",
    "expensive_indices = lis_df['price_DKK'].nlargest(4).index\n",
    "lis_df = lis_df.drop(expensive_indices)\n",
    "\n",
    "#USD\n",
    "cal_df['price'] = cal_df['price'].str.replace(r'[\\$,]', '', regex=True)\n",
    "cal_df = cal_df.rename(columns={'price': 'price_USD'})\n",
    "cal_df['price_USD'] = pd.to_numeric(cal_df['price_USD'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Process array-Type Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process amenities\n",
    "lis_df['amenities_count'] = lis_df.amenities.str.strip('[]').str.split(',').str.len()\n",
    "\n",
    "def clean_amenity(text):\n",
    "    \"\"\"Clean individual amenity strings\"\"\"\n",
    "    import re\n",
    "    text = str(text) # Convert to string if not already\n",
    "    text = text.strip().strip('\"\\'').strip('.- ') # Basic cleaning\n",
    "    text = text.encode('ascii', 'ignore').decode('ascii') # Replace unicode escape sequences with their characters\n",
    "    text = re.sub(r'\\s+', ' ', text) # Replace multiple spaces with single space\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s\\-.,:/+&æøåÆØÅ]', '', text) # Remove special characters, keeping only alphanumeric and spaces\n",
    "    text = text.lower().strip() # Convert to lowercase, strip again, and remove any remaining leading/trailing spaces\n",
    "    return text\n",
    "\n",
    "# Clean and convert amenities to comma-separated string\n",
    "lis_df['amenities'] = lis_df['amenities'].str.strip('[]').str.split(',').apply(\n",
    "    lambda x: ','.join(\n",
    "        sorted(  # Sort for consistency\n",
    "            filter(None,  # Remove empty strings\n",
    "                [clean_amenity(item) for item in x]\n",
    "            )\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "lis_df['amenities'] = lis_df['amenities'].astype('string') # Convert to string dtype\n",
    "\n",
    "# Process host verifications. Count number of verifications per host\n",
    "lis_df['host_verifications_count'] = lis_df['host_verifications'].str.strip('[]').str.split(', ').str.len()\n",
    "\n",
    "lis_df.drop(columns=['host_verifications', 'amenities'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## used to ID currency issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lis_df[['listing_url', 'price_DKK', 'price_USD']][:20]\n",
    "# Check missing DKK prices where USD price > 250\n",
    "# missing_dkk = lis_df[lis_df['price_DKK'].isna()]\n",
    "# missing_dkk_high_usd = missing_dkk[missing_dkk['price_USD'] < 500]\n",
    "# print(f\"Out of {len(missing_dkk)} listings with missing DKK prices,\")\n",
    "# print(f\"{len(missing_dkk_high_usd)} have USD prices < 500\")\n",
    "\n",
    "# Extract listing IDs from URLs and check their review dates\n",
    "# missing_dkk_listings = lis_df.loc[missing_dkk_high_usd.index, ['listing_url', 'price_DKK', 'price_USD', 'first_review', 'last_review']]\n",
    "# missing_dkk_listings = missing_dkk_listings.sort_values('first_review')\n",
    "\n",
    "# print(\"First listing's last review:\", missing_dkk_listings['first_review'].iloc[0])\n",
    "# print(\"Last listing's last review:\", missing_dkk_listings['last_review'].iloc[0])\n",
    "# # missing_dkk_listings[['listing_url', 'price_DKK', 'price_USD']]\n",
    "\n",
    "# lis_df.loc[missing_dkk_high_usd.index, ['listing_url', 'price_DKK', 'price_USD']]\n",
    "\n",
    "# Compare price columns\n",
    "# price_df = lis_df[lis_df.columns[lis_df.columns.str.startswith('price')]]\n",
    "\n",
    "# # Count missing values\n",
    "# missing_both = price_df[['price_DKK', 'price_USD']].isna().all(axis=1).sum()\n",
    "# missing_dkk_only = price_df['price_DKK'].isna().sum() - missing_both\n",
    "# missing_usd_only = price_df['price_USD'].isna().sum() - missing_both\n",
    "\n",
    "# # Count same/different prices (excluding missing)\n",
    "# valid_prices = price_df.dropna()\n",
    "# same_prices = (valid_prices['price_DKK'] == valid_prices['price_USD']).sum()\n",
    "# diff_prices = len(valid_prices) - same_prices\n",
    "\n",
    "# print(f\"Missing both prices: {missing_both}\")\n",
    "# print(f\"Missing only DKK price: {missing_dkk_only}\")\n",
    "# print(f\"Missing only USD price: {missing_usd_only}\")\n",
    "\n",
    "# print(f\"Number of listings with same prices in DKK and USD: {same_prices}\")\n",
    "# print(f\"Number of listings with different prices in DKK and USD: {diff_prices}\")\n",
    "# same_prices = (valid_prices['price_DKK'] == valid_prices['price_USD']).sum()\n",
    "# diff_prices = len(valid_prices) - same_prices\n",
    "\n",
    "\n",
    "# # Check how many rows with missing DKK prices have USD prices available\n",
    "# missing_dkk = lis_df[lis_df['price_DKK'].isna()]\n",
    "# dkk_missing_usd_available = missing_dkk['price_USD'].notna().sum()\n",
    "\n",
    "# print(f\"Out of {len(missing_dkk)} rows with missing DKK prices,\")\n",
    "# print(f\"{dkk_missing_usd_available} have USD prices available\")\n",
    "\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "# # Calculate 1st and 99th percentiles\n",
    "# lower_bound = lis_df['price_USD'].quantile(0.05)\n",
    "# upper_bound = lis_df['price_USD'].quantile(0.95)\n",
    "\n",
    "# # Filter out extreme outliers (1%)\n",
    "# clean_prices = lis_df['price_USD'][(lis_df['price_USD'] >= lower_bound) & \n",
    "#                                  (lis_df['price_USD'] <= upper_bound)]\n",
    "\n",
    "# # Plot distribution of cleaned USD prices\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.hist(clean_prices, bins=50)\n",
    "# plt.title('Distribution of USD Prices (5% Extreme Outliers Removed)')\n",
    "# plt.xlabel('Price (USD)')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.show()\n",
    "\n",
    "# # Print summary statistics\n",
    "# print(\"\\nSummary statistics for cleaned USD prices:\")\n",
    "# print(clean_prices.describe())\n",
    "# print(f\"\\nRemoved {len(lis_df['price_USD'].dropna()) - len(clean_prices)} outliers\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare average prices per listing\n",
    "cal_prices = cal_df.groupby('listing_id')['price_USD'].mean().reset_index()\n",
    "# Multiply prices under 500 by 5.9\n",
    "cal_prices.loc[cal_prices['price_USD'] < 500, 'price_USD'] *= 5.9\n",
    "\n",
    "# Merge with listings\n",
    "lis_df = lis_df.merge(\n",
    "    cal_prices,\n",
    "    left_on='id',\n",
    "    right_on='listing_id',\n",
    "    how='left'\n",
    ")\n",
    "lis_df.drop('listing_id', axis=1, inplace=True)\n",
    "\n",
    "# Fill missing DKK prices with USD prices\n",
    "lis_df.loc[lis_df['price_DKK'].isna(), 'price_DKK'] = lis_df.loc[lis_df['price_DKK'].isna(), 'price_USD']\n",
    "# Drop price_USD if no missing values in price_DKK\n",
    "if not lis_df['price_DKK'].isna().any():\n",
    "    lis_df.drop('price_USD', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis_df.to_parquet('data/processed/02_listings.parquet')\n",
    "rev_df.to_parquet('data/processed/02_reviews.parquet')\n",
    "print('rev:',rev_df.shape)\n",
    "print('lis:',lis_df.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
