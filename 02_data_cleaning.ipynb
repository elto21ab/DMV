{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setup and Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_df = pd.read_csv('data/raw/calendar2024.csv')\n",
    "lis_df = pd.read_csv('data/raw/listings2024.csv') \n",
    "rev_df = pd.read_csv('data/raw/reviews2024.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Initial Column Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove empty columns\n",
    "null_cols_lis = lis_df.columns[lis_df.isna().all()].tolist()\n",
    "lis_df = lis_df.drop(columns=null_cols_lis)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "lis_df.drop(columns=['scrape_id', 'host_name', 'picture_url', 'host_url', 'host_thumbnail_url', 'host_picture_url'], inplace=True)\n",
    "cal_df.drop(columns=['adjusted_price'], inplace=True)\n",
    "rev_df.drop(columns=['reviewer_name'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data Type Conversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def convert_to_boolean(df, columns, true_value='t'):\n",
    "    \"\"\"Convert specified columns from string indicators to boolean\"\"\"\n",
    "    for col in columns:\n",
    "        df[col] = df[col] == true_value\n",
    "    return df\n",
    "\n",
    "def convert_to_datetime(df, columns):\n",
    "    \"\"\"Convert specified columns to datetime\"\"\"\n",
    "    for col in columns:\n",
    "        df[col] = pd.to_datetime(df[col])\n",
    "    return df\n",
    "\n",
    "def convert_to_type(df, columns, dtype):\n",
    "    \"\"\"Convert specified columns to given dtype\"\"\"\n",
    "    for col in columns:\n",
    "        df[col] = df[col].astype(dtype)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Apply Type Conversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boolean conversions\n",
    "boolean_cols = ['instant_bookable', 'host_is_superhost', 'host_has_profile_pic', 'host_identity_verified', 'has_availability']\n",
    "lis_df = convert_to_boolean(lis_df, boolean_cols)\n",
    "cal_df['available'] = cal_df['available'] == 't'\n",
    "\n",
    "# Datetime conversions\n",
    "datetime_cols_lis = ['calendar_last_scraped', 'first_review', 'last_review', 'last_scraped', 'host_since']\n",
    "lis_df = convert_to_datetime(lis_df, datetime_cols_lis)\n",
    "cal_df['date'] = pd.to_datetime(cal_df['date'])\n",
    "rev_df['date'] = pd.to_datetime(rev_df['date'])\n",
    "\n",
    "# String conversions\n",
    "string_columns = ['bathrooms_text', 'neighbourhood', 'neighbourhood_cleansed', 'property_type', 'room_type', 'host_location', 'host_about', 'host_neighbourhood', 'listing_url', 'host_response_time', 'source', 'name', 'description', 'neighborhood_overview']\n",
    "lis_df = convert_to_type(lis_df, string_columns, \"string\")\n",
    "rev_df['comments'] = rev_df['comments'].astype(\"string\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Handle Percentage and Currency Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert percentage columns\n",
    "percentage_cols = ['host_response_rate', 'host_acceptance_rate']\n",
    "for col in percentage_cols:\n",
    "    lis_df = lis_df.rename(columns={col: f\"{col}_pct\"})\n",
    "    lis_df[f\"{col}_pct\"] = lis_df[f\"{col}_pct\"].str.rstrip('%').astype('float') / 100\n",
    "\n",
    "# Clean and standardize price columns\n",
    "#DKK\n",
    "lis_df['price'] = lis_df['price'].str.replace(r'[\\$,]', '', regex=True)\n",
    "lis_df = lis_df.rename(columns={'price': 'price_DKK'})\n",
    "lis_df['price_DKK'] = pd.to_numeric(lis_df['price_DKK'], errors='coerce')\n",
    "\n",
    "# Drop the 4 most expensive listings (they looked like ingenuine outliers)\n",
    "expensive_indices = lis_df['price_DKK'].nlargest(4).index\n",
    "lis_df = lis_df.drop(expensive_indices)\n",
    "\n",
    "#USD\n",
    "cal_df['price'] = cal_df['price'].str.replace(r'[\\$,]', '', regex=True)\n",
    "cal_df = cal_df.rename(columns={'price': 'price_USD'})\n",
    "cal_df['price_USD'] = pd.to_numeric(cal_df['price_USD'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Process array-Type Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process amenities\n",
    "lis_df['amenities_count'] = lis_df.amenities.str.strip('[]').str.split(',').str.len()\n",
    "\n",
    "def clean_amenity(text):\n",
    "    \"\"\"Clean individual amenity strings\"\"\"\n",
    "    import re\n",
    "    text = str(text) # Convert to string if not already\n",
    "    text = text.strip().strip('\"\\'').strip('.- ') # Basic cleaning\n",
    "    text = text.encode('ascii', 'ignore').decode('ascii') # Replace unicode escape sequences with their characters\n",
    "    text = re.sub(r'\\s+', ' ', text) # Replace multiple spaces with single space\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text) # Remove special characters, keeping only alphanumeric and spaces\n",
    "    text = text.lower().strip() # Convert to lowercase, strip again, and remove any remaining leading/trailing spaces\n",
    "    return text\n",
    "\n",
    "# Clean and convert amenities to comma-separated string\n",
    "lis_df['amenities'] = lis_df['amenities'].str.strip('[]').str.split(',').apply(\n",
    "    lambda x: ','.join(\n",
    "        sorted(  # Sort for consistency\n",
    "            filter(None,  # Remove empty strings\n",
    "                [clean_amenity(item) for item in x]\n",
    "            )\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "lis_df['amenities'] = lis_df['amenities'].astype('string') # Convert to string dtype\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Process host verifications\n",
    "# Count number of verifications per host\n",
    "lis_df['host_verifications_count'] = lis_df['host_verifications'].str.strip('[]').str.split(', ').str.len()\n",
    "lis_df['host_verifications'] = lis_df['host_verifications'].str.strip('[]').str.replace(\"'\", \"\").str.split(', ')\n",
    "# Create one-hot encoded columns\n",
    "verification_dummies = lis_df['host_verifications'].str.join('|').str.get_dummies()\n",
    "verification_dummies = verification_dummies.add_prefix('verification_')\n",
    "lis_df = pd.concat([lis_df, verification_dummies], axis=1)\n",
    "\n",
    "lis_df.drop(columns=['host_verifications', 'amenities'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis_df.to_parquet('data/processed/02_listings.parquet')\n",
    "cal_df.to_parquet('data/processed/02_calendar.parquet')\n",
    "rev_df.to_parquet('data/processed/02_reviews.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
