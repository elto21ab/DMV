{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setup and Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_df = pd.read_csv('data/raw/calendar2024.csv')\n",
    "lis_df = pd.read_csv('data/raw/listings2024.csv') \n",
    "rev_df = pd.read_csv('data/raw/reviews2024.csv')\n",
    "print('rev:',rev_df.shape)\n",
    "print('lis:',lis_df.shape)\n",
    "print('cal:',cal_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Initial Column Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove empty columns\n",
    "null_cols_lis = lis_df.columns[lis_df.isna().all()].tolist()\n",
    "lis_df = lis_df.drop(columns=null_cols_lis)\n",
    "\n",
    "# Drop unnecessary columns from listings data\n",
    "lis_df.drop(columns=['scrape_id', 'host_name', 'picture_url', 'host_url', 'host_thumbnail_url', \n",
    "                     'host_picture_url', 'host_listings_count', 'calculated_host_listings_count', \n",
    "                     'calculated_host_listings_count_entire_homes', 'calculated_host_listings_count_private_rooms', \n",
    "                     'calculated_host_listings_count_shared_rooms', 'host_listings_count', 'calculated_host_listings_count', \n",
    "                     'calculated_host_listings_count_entire_homes', 'calculated_host_listings_count_private_rooms', \n",
    "                     'calculated_host_listings_count_shared_rooms', 'number_of_reviews_l30d', 'number_of_reviews_ltm'], inplace=True)\n",
    "\n",
    "# cal_df.drop(columns=['adjusted_price'], inplace=True)\n",
    "rev_df.drop(columns=['reviewer_name'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis_df['superhost'] = lis_df['host_is_superhost']\n",
    "lis_df.drop(['host_is_superhost'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data Type Conversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def convert_to_boolean(df, columns, true_value='t'):\n",
    "    \"\"\"Convert specified columns from string indicators to boolean\"\"\"\n",
    "    for col in columns:\n",
    "        df[col] = df[col] == true_value\n",
    "    return df\n",
    "\n",
    "def convert_to_datetime(df, columns):\n",
    "    \"\"\"Convert specified columns to datetime\"\"\"\n",
    "    for col in columns:\n",
    "        df[col] = pd.to_datetime(df[col])\n",
    "    return df\n",
    "\n",
    "def convert_to_type(df, columns, dtype):\n",
    "    \"\"\"Convert specified columns to given dtype\"\"\"\n",
    "    for col in columns:\n",
    "        df[col] = df[col].astype(dtype)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Apply Type Conversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boolean conversions\n",
    "boolean_cols = ['instant_bookable', 'host_has_profile_pic', 'host_identity_verified', 'has_availability']\n",
    "lis_df = convert_to_boolean(lis_df, boolean_cols)\n",
    "# cal_df['available'] = cal_df['available'] == 't'\n",
    "\n",
    "# Datetime conversions\n",
    "datetime_cols_lis = ['calendar_last_scraped', 'first_review', 'last_review', 'last_scraped', 'host_since']\n",
    "lis_df = convert_to_datetime(lis_df, datetime_cols_lis)\n",
    "# cal_df['date'] = pd.to_datetime(cal_df['date'])\n",
    "rev_df['date'] = pd.to_datetime(rev_df['date'])\n",
    "\n",
    "# String conversions\n",
    "string_columns = ['bathrooms_text', 'neighbourhood', 'neighbourhood_cleansed', 'property_type', 'room_type', 'host_location', 'host_about', 'host_neighbourhood', 'listing_url', 'host_response_time', 'source', 'name', 'description', 'neighborhood_overview']\n",
    "lis_df = convert_to_type(lis_df, string_columns, \"string\")\n",
    "rev_df['comments'] = rev_df['comments'].astype(\"string\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Handle Percentage and Currency Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert percentage columns\n",
    "percentage_cols = ['host_response_rate', 'host_acceptance_rate']\n",
    "for col in percentage_cols:\n",
    "    lis_df = lis_df.rename(columns={col: f\"{col}_pct\"})\n",
    "    lis_df[f\"{col}_pct\"] = lis_df[f\"{col}_pct\"].str.rstrip('%').astype('float') / 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Process array-Type Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process amenities\n",
    "lis_df['amenities_count'] = lis_df.amenities.str.strip('[]').str.split(',').str.len()\n",
    "\n",
    "def clean_amenity(text):\n",
    "    \"\"\"Clean individual amenity strings\"\"\"\n",
    "    import re\n",
    "    text = str(text) # Convert to string if not already\n",
    "    text = text.strip().strip('\"\\'').strip('.- ') # Basic cleaning\n",
    "    text = text.encode('ascii', 'ignore').decode('ascii') # Replace unicode escape sequences with their characters\n",
    "    text = re.sub(r'\\s+', ' ', text) # Replace multiple spaces with single space\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s\\-.,:/+&æøåÆØÅ]', '', text) # Remove special characters, keeping only alphanumeric and spaces\n",
    "    text = text.lower().strip() # Convert to lowercase, strip again, and remove any remaining leading/trailing spaces\n",
    "    return text\n",
    "\n",
    "# Clean and convert amenities to comma-separated string\n",
    "lis_df['amenities'] = lis_df['amenities'].str.strip('[]').str.split(',').apply(\n",
    "    lambda x: ','.join(\n",
    "        sorted(  # Sort for consistency\n",
    "            filter(None,  # Remove empty strings\n",
    "                [clean_amenity(item) for item in x]\n",
    "            )\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "lis_df['amenities'] = lis_df['amenities'].astype('string') # Convert to string dtype\n",
    "\n",
    "# Process host verifications. Count number of verifications per host\n",
    "lis_df['host_verifications_count'] = lis_df['host_verifications'].str.strip('[]').str.split(', ').str.len()\n",
    "\n",
    "lis_df.drop(columns=['host_verifications', 'amenities'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Handle Missing Values (Imputation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20905 entries, 0 to 20904\n",
      "Data columns (total 59 columns):\n",
      " #   Column                       Non-Null Count  Dtype         \n",
      "---  ------                       --------------  -----         \n",
      " 0   id                           20905 non-null  int64         \n",
      " 1   listing_url                  20905 non-null  string        \n",
      " 2   last_scraped                 20905 non-null  datetime64[ns]\n",
      " 3   source                       20905 non-null  string        \n",
      " 4   name                         20905 non-null  string        \n",
      " 5   description                  20232 non-null  string        \n",
      " 6   neighborhood_overview        8984 non-null   string        \n",
      " 7   host_id                      20905 non-null  int64         \n",
      " 8   host_since                   20904 non-null  datetime64[ns]\n",
      " 9   host_location                20905 non-null  string        \n",
      " 10  host_about                   8863 non-null   string        \n",
      " 11  host_response_time           20905 non-null  string        \n",
      " 12  host_response_rate_pct       14439 non-null  float64       \n",
      " 13  host_acceptance_rate_pct     20905 non-null  float64       \n",
      " 14  host_neighbourhood           5416 non-null   string        \n",
      " 15  host_total_listings_count    20905 non-null  float64       \n",
      " 16  host_has_profile_pic         20905 non-null  bool          \n",
      " 17  host_identity_verified       20905 non-null  bool          \n",
      " 18  neighbourhood                20905 non-null  string        \n",
      " 19  neighbourhood_cleansed       20905 non-null  string        \n",
      " 20  latitude                     20905 non-null  float64       \n",
      " 21  longitude                    20905 non-null  float64       \n",
      " 22  property_type                20905 non-null  string        \n",
      " 23  room_type                    20905 non-null  string        \n",
      " 24  accommodates                 20905 non-null  int64         \n",
      " 25  bathrooms                    13656 non-null  float64       \n",
      " 26  bathrooms_text               20899 non-null  string        \n",
      " 27  bedrooms                     20296 non-null  float64       \n",
      " 28  beds                         13656 non-null  float64       \n",
      " 29  price_DKK                    20905 non-null  float64       \n",
      " 30  minimum_nights               20905 non-null  int64         \n",
      " 31  maximum_nights               20905 non-null  int64         \n",
      " 32  minimum_minimum_nights       20905 non-null  int64         \n",
      " 33  maximum_minimum_nights       20905 non-null  int64         \n",
      " 34  minimum_maximum_nights       20905 non-null  int64         \n",
      " 35  maximum_maximum_nights       20905 non-null  int64         \n",
      " 36  minimum_nights_avg_ntm       20905 non-null  float64       \n",
      " 37  maximum_nights_avg_ntm       20905 non-null  float64       \n",
      " 38  has_availability             20905 non-null  bool          \n",
      " 39  availability_30              20905 non-null  int64         \n",
      " 40  availability_60              20905 non-null  int64         \n",
      " 41  availability_90              20905 non-null  int64         \n",
      " 42  availability_365             20905 non-null  int64         \n",
      " 43  calendar_last_scraped        20905 non-null  datetime64[ns]\n",
      " 44  number_of_reviews            20905 non-null  int64         \n",
      " 45  first_review                 17687 non-null  datetime64[ns]\n",
      " 46  last_review                  17687 non-null  datetime64[ns]\n",
      " 47  review_scores_rating         17687 non-null  float64       \n",
      " 48  review_scores_accuracy       17663 non-null  float64       \n",
      " 49  review_scores_cleanliness    17663 non-null  float64       \n",
      " 50  review_scores_checkin        17663 non-null  float64       \n",
      " 51  review_scores_communication  17663 non-null  float64       \n",
      " 52  review_scores_location       17662 non-null  float64       \n",
      " 53  review_scores_value          17662 non-null  float64       \n",
      " 54  instant_bookable             20905 non-null  bool          \n",
      " 55  reviews_per_month            17687 non-null  float64       \n",
      " 56  superhost                    20681 non-null  object        \n",
      " 57  amenities_count              20905 non-null  int64         \n",
      " 58  host_verifications_count     20905 non-null  float64       \n",
      "dtypes: bool(4), datetime64[ns](5), float64(20), int64(15), object(1), string(14)\n",
      "memory usage: 8.9+ MB\n"
     ]
    }
   ],
   "source": [
    "lis_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing Values Analysis for Listings:\n",
      "--------------------------------------------------\n",
      "                             Missing Values  Missing Percentage\n",
      "host_neighbourhood                    15489               74.09\n",
      "host_about                            12042               57.60\n",
      "neighborhood_overview                 11921               57.02\n",
      "bathrooms                              7249               34.68\n",
      "beds                                   7249               34.68\n",
      "host_response_rate_pct                 6466               30.93\n",
      "review_scores_communication            3242               15.51\n",
      "review_scores_value                    3243               15.51\n",
      "review_scores_location                 3243               15.51\n",
      "review_scores_accuracy                 3242               15.51\n",
      "review_scores_cleanliness              3242               15.51\n",
      "review_scores_checkin                  3242               15.51\n",
      "first_review                           3218               15.39\n",
      "reviews_per_month                      3218               15.39\n",
      "last_review                            3218               15.39\n",
      "review_scores_rating                   3218               15.39\n",
      "description                             673                3.22\n",
      "bedrooms                                609                2.91\n",
      "superhost                               224                1.07\n",
      "bathrooms_text                            6                0.03\n",
      "host_since                                1                0.00\n",
      "\n",
      "Total rows in dataset: 20905\n",
      "\n",
      "Missing Values Analysis for Reviews:\n",
      "--------------------------------------------------\n",
      "No missing values found!\n",
      "\n",
      "Total rows in dataset: 366636\n"
     ]
    }
   ],
   "source": [
    "# Function to analyze missing values\n",
    "def analyze_missing_values(df, df_name):\n",
    "    # Calculate missing values\n",
    "    missing = df.isnull().sum()\n",
    "    missing_percent = (df.isnull().sum() / len(df)) * 100\n",
    "    \n",
    "    # Create a summary DataFrame\n",
    "    missing_info = pd.DataFrame({\n",
    "        'Missing Values': missing,\n",
    "        'Missing Percentage': missing_percent.round(2)\n",
    "    })\n",
    "    \n",
    "    # Only show columns with missing values, sorted by percentage\n",
    "    missing_info = missing_info[missing_info['Missing Values'] > 0].sort_values(\n",
    "        'Missing Percentage', ascending=False\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nMissing Values Analysis for {df_name}:\")\n",
    "    print(\"-\" * 50)\n",
    "    if len(missing_info) > 0:\n",
    "        print(missing_info)\n",
    "    else:\n",
    "        print(\"No missing values found!\")\n",
    "    print(f\"\\nTotal rows in dataset: {len(df)}\")\n",
    "\n",
    "# Analyze both datasets\n",
    "analyze_missing_values(lis_df, \"Listings\")\n",
    "analyze_missing_values(rev_df, \"Reviews\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Price Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix price columns\n",
    "#DKK\n",
    "lis_df['price'] = lis_df['price'].str.replace(r'[\\$,]', '', regex=True)\n",
    "lis_df = lis_df.rename(columns={'price': 'price_DKK'})\n",
    "lis_df['price_DKK'] = pd.to_numeric(lis_df['price_DKK'], errors='coerce')\n",
    "\n",
    "# Drop the 4 most expensive listings (they looked like ingenuine outliers)\n",
    "expensive_indices = lis_df['price_DKK'].nlargest(4).index\n",
    "lis_df = lis_df.drop(expensive_indices)\n",
    "\n",
    "#USD\n",
    "cal_df['price'] = cal_df['price'].str.replace(r'[\\$,]', '', regex=True)\n",
    "cal_df = cal_df.rename(columns={'price': 'price_USD'})\n",
    "cal_df['price_USD'] = pd.to_numeric(cal_df['price_USD'], errors='coerce')\n",
    "\n",
    "\n",
    "# Prepare average prices per listing\n",
    "cal_prices = cal_df.groupby('listing_id')['price_USD'].mean().reset_index()\n",
    "# Multiply prices under 500 by 5.9\n",
    "cal_prices.loc[cal_prices['price_USD'] < 500, 'price_USD'] *= 5.9\n",
    "\n",
    "# Merge with listings\n",
    "lis_df = lis_df.merge(\n",
    "    cal_prices,\n",
    "    left_on='id',\n",
    "    right_on='listing_id',\n",
    "    how='left'\n",
    ")\n",
    "lis_df.drop('listing_id', axis=1, inplace=True)\n",
    "\n",
    "# Fill missing DKK prices with USD prices\n",
    "lis_df.loc[lis_df['price_DKK'].isna(), 'price_DKK'] = lis_df.loc[lis_df['price_DKK'].isna(), 'price_USD']\n",
    "# Drop price_USD if no missing values in price_DKK\n",
    "if not lis_df['price_DKK'].isna().any():\n",
    "    lis_df.drop('price_USD', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Listing Data Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Host fields\n",
    "host_cols_to_impute = {\n",
    "    'host_acceptance_rate_pct': 0.0,  # host_acceptance_rate_pct\n",
    "    'host_total_listings_count': 1,  # Used to calculate host_listings_ratio\n",
    "    'host_verifications_count': 0,  # host_verifications_count\n",
    "    'host_response_time': '',  # host_response_time\n",
    "    'host_location': 'Copenhagen, Denmark',  # host_location\n",
    "    'host_since': pd.NaT  # Used to calculate host_experience_years\n",
    "}\n",
    "\n",
    "for col, value in host_cols_to_impute.items():\n",
    "    lis_df[col] = lis_df[col].fillna(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accommodation fields\n",
    "accommodation_cols_to_impute = {\n",
    "    'room_type': 'Unknown',  # room_type\n",
    "    'property_type': 'Unknown',  # property_type\n",
    "    'neighbourhood': 'Unknown',  # neighborhood\n",
    "    'amenities_count': 0,  # amenities_count\n",
    "    'accommodates': 1,  # accommodates\n",
    "    'has_availability': False,  # has_availability\n",
    "    'instant_bookable': False  # instant_bookable\n",
    "}\n",
    "\n",
    "for col, value in accommodation_cols_to_impute.items():\n",
    "    lis_df[col] = lis_df[col].fillna(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listings fields\n",
    "misc_cols_to_impute = {\n",
    "    'has_availability': False,  # has_availability\n",
    "    'instant_bookable': False  # instant_bookable\n",
    "}\n",
    "\n",
    "for col, value in misc_cols_to_impute.items():\n",
    "    lis_df[col] = lis_df[col].fillna(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Review Data Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the missing values are not missing at random, we will not impute them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Save Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lis_df.to_parquet('data/processed/02_listings.parquet')\n",
    "#rev_df.to_parquet('data/processed/02_reviews.parquet')\n",
    "#print('rev:',rev_df.shape)\n",
    "#print('lis:',lis_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " —————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reasoning for Currency Issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lis_df[['listing_url', 'price_DKK', 'price_USD']][:20]\n",
    "# Check missing DKK prices where USD price > 250\n",
    "# missing_dkk = lis_df[lis_df['price_DKK'].isna()]\n",
    "# missing_dkk_high_usd = missing_dkk[missing_dkk['price_USD'] < 500]\n",
    "# print(f\"Out of {len(missing_dkk)} listings with missing DKK prices,\")\n",
    "# print(f\"{len(missing_dkk_high_usd)} have USD prices < 500\")\n",
    "\n",
    "# Extract listing IDs from URLs and check their review dates\n",
    "# missing_dkk_listings = lis_df.loc[missing_dkk_high_usd.index, ['listing_url', 'price_DKK', 'price_USD', 'first_review', 'last_review']]\n",
    "# missing_dkk_listings = missing_dkk_listings.sort_values('first_review')\n",
    "\n",
    "# print(\"First listing's last review:\", missing_dkk_listings['first_review'].iloc[0])\n",
    "# print(\"Last listing's last review:\", missing_dkk_listings['last_review'].iloc[0])\n",
    "# # missing_dkk_listings[['listing_url', 'price_DKK', 'price_USD']]\n",
    "\n",
    "# lis_df.loc[missing_dkk_high_usd.index, ['listing_url', 'price_DKK', 'price_USD']]\n",
    "\n",
    "# Compare price columns\n",
    "# price_df = lis_df[lis_df.columns[lis_df.columns.str.startswith('price')]]\n",
    "\n",
    "# # Count missing values\n",
    "# missing_both = price_df[['price_DKK', 'price_USD']].isna().all(axis=1).sum()\n",
    "# missing_dkk_only = price_df['price_DKK'].isna().sum() - missing_both\n",
    "# missing_usd_only = price_df['price_USD'].isna().sum() - missing_both\n",
    "\n",
    "# # Count same/different prices (excluding missing)\n",
    "# valid_prices = price_df.dropna()\n",
    "# same_prices = (valid_prices['price_DKK'] == valid_prices['price_USD']).sum()\n",
    "# diff_prices = len(valid_prices) - same_prices\n",
    "\n",
    "# print(f\"Missing both prices: {missing_both}\")\n",
    "# print(f\"Missing only DKK price: {missing_dkk_only}\")\n",
    "# print(f\"Missing only USD price: {missing_usd_only}\")\n",
    "\n",
    "# print(f\"Number of listings with same prices in DKK and USD: {same_prices}\")\n",
    "# print(f\"Number of listings with different prices in DKK and USD: {diff_prices}\")\n",
    "# same_prices = (valid_prices['price_DKK'] == valid_prices['price_USD']).sum()\n",
    "# diff_prices = len(valid_prices) - same_prices\n",
    "\n",
    "\n",
    "# # Check how many rows with missing DKK prices have USD prices available\n",
    "# missing_dkk = lis_df[lis_df['price_DKK'].isna()]\n",
    "# dkk_missing_usd_available = missing_dkk['price_USD'].notna().sum()\n",
    "\n",
    "# print(f\"Out of {len(missing_dkk)} rows with missing DKK prices,\")\n",
    "# print(f\"{dkk_missing_usd_available} have USD prices available\")\n",
    "\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "# # Calculate 1st and 99th percentiles\n",
    "# lower_bound = lis_df['price_USD'].quantile(0.05)\n",
    "# upper_bound = lis_df['price_USD'].quantile(0.95)\n",
    "\n",
    "# # Filter out extreme outliers (1%)\n",
    "# clean_prices = lis_df['price_USD'][(lis_df['price_USD'] >= lower_bound) & \n",
    "#                                  (lis_df['price_USD'] <= upper_bound)]\n",
    "\n",
    "# # Plot distribution of cleaned USD prices\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.hist(clean_prices, bins=50)\n",
    "# plt.title('Distribution of USD Prices (5% Extreme Outliers Removed)')\n",
    "# plt.xlabel('Price (USD)')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.show()\n",
    "\n",
    "# # Print summary statistics\n",
    "# print(\"\\nSummary statistics for cleaned USD prices:\")\n",
    "# print(clean_prices.describe())\n",
    "# print(f\"\\nRemoved {len(lis_df['price_USD'].dropna()) - len(clean_prices)} outliers\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
