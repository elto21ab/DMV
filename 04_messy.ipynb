{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "lis_df = pd.read_parquet('data/processed/05_listings.parquet') \n",
    "# rev_df = pd.read_parquet('data/processed/05_sentiment_bert.parquet')\n",
    "print(\"Listings shape:\", lis_df.shape)\n",
    "# print(\"Reviews shape:\", rev_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "lis_df = pd.read_parquet('data/processed/05_listings.parquet') \n",
    "lis_df['id'] = lis_df['id'].astype('category')\n",
    "lis_df['host_id'] = lis_df['host_id'].astype('category')\n",
    "lis_df['property_type'] = lis_df['property_type'].astype('category')\n",
    "lis_df['room_type'] = lis_df['room_type'].astype('category')\n",
    "lis_df['host_neighbourhood'] = lis_df['host_neighbourhood'].astype('category')\n",
    "\n",
    "lis_df['host_response_time'] = pd.Categorical(\n",
    "    lis_df['host_response_time'],\n",
    "    categories=['within an hour', 'within a few hours', 'within a day', 'a few days or more', 'never'],\n",
    "    ordered=True\n",
    ")\n",
    "lis_df = lis_df.drop(['host_acceptance_rate_pct'], axis=1)\n",
    "\n",
    "lis_df.to_parquet('data/processed/06_listings.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis_df.to_parquet('data/processed/06_listings.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lis_df.info())\n",
    "lis_df[:3]\n",
    "lis_df.host_response_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert id column to string to avoid showing numeric stats\n",
    "# Convert id column to string and ensure it's treated as categorical\n",
    "lis_df['id'] = lis_df['id'].astype('category')\n",
    "lis_df['host_id'] = lis_df['host_id'].astype('category')\n",
    "lis_df['property_type'] = lis_df['property_type'].astype('category')\n",
    "lis_df['room_type'] = lis_df['room_type'].astype('category')\n",
    "lis_df['host_neighbourhood'] = lis_df['host_neighbourhood'].astype('category')\n",
    "\n",
    "lis_df['host_response_time'] = pd.Categorical(\n",
    "    lis_df['host_response_time'],\n",
    "    categories=['within an hour', 'within a few hours', 'within a day', 'a few days or more', 'never'],\n",
    "    ordered=True\n",
    ")\n",
    "\n",
    "def create_summary_table(df):\n",
    "    \"\"\"Create a summary table with statistics for each column.\"\"\"\n",
    "    # Initialize empty lists to store column statistics\n",
    "    stats = []\n",
    "    \n",
    "    for col in df.columns:\n",
    "        # Get number of unique values\n",
    "        n_unique = df[col].nunique()\n",
    "        \n",
    "        # Get number of null values\n",
    "        n_null = df[col].isnull().sum()\n",
    "        \n",
    "        # Get min and max values (if applicable)\n",
    "        try:\n",
    "            min_val = df[col].min()\n",
    "            max_val = df[col].max()\n",
    "        except:\n",
    "            min_val = '-'\n",
    "            max_val = '-'\n",
    "            \n",
    "        # Get mean (if applicable)\n",
    "        try:\n",
    "            mean_val = df[col].mean()\n",
    "        except:\n",
    "            mean_val = '-'\n",
    "            \n",
    "        stats.append({\n",
    "            'Name': col,\n",
    "            'No. of Unique': n_unique,\n",
    "            'No. of Null': n_null,\n",
    "            'Min. Value': min_val,\n",
    "            'Max. Value': max_val,\n",
    "            'Mean': mean_val\n",
    "        })\n",
    "    \n",
    "    # Create DataFrame from stats\n",
    "    summary_df = pd.DataFrame(stats)\n",
    "    \n",
    "    # Format numeric values\n",
    "    summary_df['Mean'] = pd.to_numeric(summary_df['Mean'], errors='ignore')\n",
    "    numeric_cols = summary_df.select_dtypes(include=['float64', 'int64']).columns\n",
    "    summary_df[numeric_cols] = summary_df[numeric_cols].round(6)\n",
    "    \n",
    "    return summary_df\n",
    "\n",
    "# Create and display summary table\n",
    "summary_table = create_summary_table(lis_df)\n",
    "print(\"Table 1: Summary of Dataset Columns (Excluding Description)\")\n",
    "\n",
    "display(summary_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_descriptions = {\n",
    "    'id': 'Unique identifier for each listing',\n",
    "    'description': 'Free-text description provided by the host',\n",
    "    'host_id': 'Unique identifier for each host',\n",
    "    'host_response_time': 'How quickly the host typically responds to guests',\n",
    "    'host_neighbourhood': 'Area where the hosting property is located',\n",
    "    'host_total_listings_count': 'Total number of properties listed by the host',\n",
    "    'host_has_profile_pic': 'Boolean (T/F); do host have a profile picture',\n",
    "    'host_identity_verified': 'Boolean (T/F) indicating if host\\'s identity is verified',\n",
    "    'latitude': 'Geographic latitude of the property',\n",
    "    'longitude': 'Geographic longitude of the property',\n",
    "    'property_type': 'Type of property (e.g., Apartment, House)',\n",
    "    'room_type': 'Type of room arrangement offered',\n",
    "    'accommodates': 'Maximum guests that can be accommodated',\n",
    "    'bathrooms': 'Number of bathrooms available',\n",
    "    'bedrooms': 'Number of bedrooms available',\n",
    "    'beds': 'Total number of beds available',\n",
    "    'price_DKK': 'Nightly price in Danish Krone',\n",
    "    'number_of_reviews': 'Total number of reviews received',\n",
    "    'review_scores_rating': 'Overall rating from reviews (1-5)',\n",
    "    'review_scores_accuracy': 'Rating for listing accuracy (1-5)',\n",
    "    'review_scores_cleanliness': 'Rating for cleanliness (1-5)',\n",
    "    'review_scores_checkin': 'Rating for check-in experience (1-5)',\n",
    "    'review_scores_communication': 'Rating for host communication (1-5)',\n",
    "    'review_scores_location': 'Rating for location (1-5)',\n",
    "    'review_scores_value': 'Rating for value for money (1-5)',\n",
    "    'instant_bookable': 'Boolean (T/F); is instant booking available',\n",
    "    'reviews_per_month': 'Average number of reviews received per month',\n",
    "    'superhost': 'Boolean (T/F); is the host a Superhost',\n",
    "    'host_verifications_count': 'Number of verifications completed by the host',\n",
    "    'listings_in_neighborhood': 'Total number of listings in the same neighborhood',\n",
    "    'host_experience_years': 'Number of years the host has been active',\n",
    "    'yearly_review': 'Average reviews a listing recieves per year',\n",
    "    'active_period_years': 'Number of years the listing has been active',\n",
    "    'avg_sentiment': 'Average sentiment score from review analysis',\n",
    "    'n_bookings': 'Total number of bookings received',\n",
    "    'amenity_category': 'Ordinally level of amenities (low/medium/high)',\n",
    "    'location_category': 'Distance to center ordinal (4 categories)'\n",
    "}\n",
    "\n",
    "desc_df = pd.DataFrame(list(column_descriptions.items()), columns=['Name', 'Description'])\n",
    "desc_df.index = range(len(desc_df))\n",
    "desc_df.index.name = '#'\n",
    "display(desc_df.style.set_properties(**{'text-align': 'left'}, subset=['Name', 'Description']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "sentiment_data = {\n",
    "    'Metric': ['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max'],\n",
    "    'Value': [366636, 0.581580, 0.257366, -0.972317, 0.351762, 0.639770, 0.786318, 0.995148]\n",
    "}\n",
    "\n",
    "\n",
    "df = pd.DataFrame(sentiment_data)\n",
    "print(\"  Sentiment Distribution \")\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich.console import Console\n",
    "from rich.table import Table\n",
    "import pandas as pd\n",
    "\n",
    "def create_pretty_stats(df):\n",
    "    console = Console()\n",
    "    table = Table(show_header=True, header_style=\"bold\")\n",
    "    \n",
    "    # Add columns\n",
    "    table.add_column(\"#\", style=\"dim\")\n",
    "    table.add_column(\"Name\")\n",
    "    table.add_column(\"No. of Unique\", justify=\"right\")\n",
    "    table.add_column(\"No. of Null\", justify=\"right\")\n",
    "    table.add_column(\"Min. Value\", justify=\"right\")\n",
    "    table.add_column(\"Max. Value\", justify=\"right\")\n",
    "    table.add_column(\"Mean\", justify=\"right\")\n",
    "    \n",
    "    for i, col in enumerate(df.columns):\n",
    "        stats = {\n",
    "            'unique': df[col].nunique(),\n",
    "            'null': df[col].isnull().sum(),\n",
    "            'min': f\"{df[col].min():.6f}\" if pd.api.types.is_numeric_dtype(df[col]) and not pd.isna(df[col].min()) else '-',\n",
    "            'max': f\"{df[col].max():.6f}\" if pd.api.types.is_numeric_dtype(df[col]) and not pd.isna(df[col].max()) else '-',\n",
    "            'mean': f\"{df[col].mean():.6f}\" if pd.api.types.is_numeric_dtype(df[col]) and not pd.isna(df[col].mean()) else '-'\n",
    "        }\n",
    "        \n",
    "        table.add_row(\n",
    "            str(i),\n",
    "            col,\n",
    "            str(stats['unique']),\n",
    "            str(stats['null']),\n",
    "            str(stats['min']),\n",
    "            str(stats['max']),\n",
    "            str(stats['mean'])\n",
    "        )\n",
    "    \n",
    "    console.print(table)\n",
    "# # Create DataFrame\n",
    "df = pd.DataFrame(lis_df)\n",
    "create_summary_stats(df)\n",
    "# # Print table\n",
    "# print(tabulate(df, headers='keys', tablefmt='simple', showindex=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis_df = lis_df.drop(['active_period_years', 'host_acceptance_rate_pct', 'listing_url'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis_df['location_category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(rev_df.info())\n",
    "rev_df[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate reviews before merging\n",
    "reviews_agg = rev_df.groupby('listing_id').agg({\n",
    "    'date': lambda x: (x.max() - x.min()).days / 365.25,  # Get range of dates\n",
    "    'sentiment_score_1_5': 'mean',  # Average sentiment and count\n",
    "    'reviewer_id': 'nunique' \n",
    "}).rename(columns={\n",
    "    'date': 'active_period_years',\n",
    "    'sentiment_score_1_5': 'avg_sentiment',\n",
    "    'reviewer_id': 'n_bookings'\n",
    "}).reset_index()\n",
    "\n",
    "# Merge with listings (now one-to-one)\n",
    "lis_1t1 = lis_df.merge(\n",
    "    reviews_agg,\n",
    "    left_on='id',\n",
    "    right_on='listing_id',\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### smth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis_1t1[['id','review_scores_rating','avg_sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lis_1t1.drop(columns=[ 'host_identity_verified', 'instant_bookable'], inplace=True)\n",
    "# lis_1t1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'host_has_profile_pic', 'description'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'host_acceptance_rate_pct',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis_1t1.drop(columns=['name','description','host_response_rate_pct','neighbourhood_cleansed',  'has_availability', 'listing_id', 'host_since'], inplace=True) \n",
    "\n",
    "lis_1t1.drop(columns=['price_vs_room_type', 'price_per_person', 'price_per_bedroom', 'neighborhood_avg_price','price_vs_neighborhood','room_type_avg_price', 'host_listings_ratio' ], inplace=True)\n",
    "lis_1t1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis_df['host_identity_verified']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = rev_df.groupby('listing_id')[['date', 'sentiment_score_1_5', 'comments', 'reviewer_id']].reset_index()\n",
    "\n",
    "# Merge with listings\n",
    "lis_df = lis_df.merge(\n",
    "    reviews,\n",
    "    left_on='id',\n",
    "    right_on='listing_id',\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_df[rev_df['listing_id'] == 1188302911099164911]['comments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count missing avg_sentiment values\n",
    "missing_sentiment = lis_1t1['avg_sentiment'].isna().sum()\n",
    "total_rows = len(lis_1t1)\n",
    "print(f\"Missing sentiment scores: {missing_sentiment} out of {total_rows} rows ({missing_sentiment/total_rows:.1%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count missing review_scores_rating values\n",
    "missing_ratings = lis_1t1['review_scores_rating'].isna().sum()\n",
    "total_rows = len(lis_1t1)\n",
    "print(f\"Missing review scores: {missing_ratings} out of {total_rows} rows ({missing_ratings/total_rows:.1%})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_columns = [col for col in lis_df.columns if 'review' in col.lower()]\n",
    "print(\"Columns containing 'review':\")\n",
    "for col in review_columns:\n",
    "    print(f\"- {col}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO in SQL\n",
    "# Response Quality: encode ordinal rating of each possible response time category\n",
    "# lis_df['host_response_time']\n",
    "\n",
    "# How many listings a host own (listings_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_missing_values(df, df_name):\n",
    "    # Calculate missing values\n",
    "    missing = df.isnull().sum()\n",
    "    missing_percent = (df.isnull().sum() / len(df)) * 100\n",
    "    \n",
    "    # Create a summary DataFrame\n",
    "    missing_info = pd.DataFrame({\n",
    "        'Missing Values': missing,\n",
    "        'Missing Percentage': missing_percent.round(2)\n",
    "    })\n",
    "    \n",
    "    # Only show columns with missing values, sorted by percentage\n",
    "    missing_info = missing_info[missing_info['Missing Values'] > 0].sort_values(\n",
    "        'Missing Percentage', ascending=False\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nMissing Values Analysis for {df_name}:\")\n",
    "    print(\"-\" * 50)\n",
    "    if len(missing_info) > 0:\n",
    "        print(missing_info)\n",
    "    else:\n",
    "        print(\"No missing values found!\")\n",
    "    print(f\"\\nTotal rows in dataset: {len(df)}\")\n",
    "\n",
    "# Analyze both datasets\n",
    "analyze_missing_values(lis_df, \"Listings\")\n",
    "analyze_missing_values(rev_df, \"Reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missing values in reviews.comments\n",
    "print(\"\\nMissing values in reviews.beds:\")\n",
    "print(f\"Number of missing beds: {lis_df['beds'].isna().sum()}\")\n",
    "print(f\"Percentage missing: {(lis_df['beds'].isna().sum() / len(lis_df) * 100):.2f}%\")\n",
    "\n",
    "# Show sample of reviews with missing comments\n",
    "print(\"\\nSample of reviews with missing beds:\")\n",
    "display(lis_df[lis_df['beds'].isna()].head())\n",
    "# Display beds and bathrooms for rows where beds are missing\n",
    "print(\"\\nBeds and bathrooms for listings with missing beds:\")\n",
    "display(lis_df[lis_df['beds'].isna()][['beds', 'bathrooms', 'bathrooms_text']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis_df[lis_df.columns[lis_df.columns.str.contains('reviews_')]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle half baths and NAs in bathrooms_text\n",
    "# First convert to float to avoid dtype warning\n",
    "half_bath_mask = lis_df['bathrooms_text'].isin(['Half-bath', 'Shared half-bath', 'Private half-bath'])\n",
    "lis_df.loc[half_bath_mask, 'bathrooms_text'] = lis_df.loc[half_bath_mask, 'bathrooms_text'].astype(float).fillna(0.5)\n",
    "\n",
    "# Handle NAs with explicit float conversion\n",
    "lis_df['bathrooms_text'] = lis_df['bathrooms_text'].astype(float).fillna(0.0)\n",
    "\n",
    "# Extract numeric values from bathrooms_text\n",
    "# Convert to string first before using str accessor\n",
    "lis_df['bathrooms_text'] = lis_df['bathrooms_text'].astype(str).str.extract(r'^(\\d+\\.?\\d?)').astype(float)\n",
    "\n",
    "# Fill NaN bathrooms values with bathrooms_text values\n",
    "lis_df.loc[lis_df['bathrooms'].isna(), 'bathrooms'] = lis_df.loc[lis_df['bathrooms'].isna(), 'bathrooms_text']\n",
    "print(len(lis_df['bathrooms_text'].unique()), lis_df['bathrooms_text'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis_df['bathrooms_text'].unique()\n",
    "# Aggregate reviews before merging\n",
    "lis_df[['bathrooms', 'bathrooms_text']].dtypes\n",
    "\n",
    "# Show sample where bathrooms and bathrooms_text values differ and get total count\n",
    "diff_bath = lis_df[['bathrooms', 'bathrooms_text']].loc[lis_df['bathrooms'] != lis_df['bathrooms_text']]\n",
    "print(f\"Total rows with different values: {len(diff_bath)}\")\n",
    "print(\"\\nSample of differences:\")\n",
    "display(diff_bath[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaN bathrooms values with bathrooms_text values\n",
    "lis_df.loc[lis_df['bathrooms'].isna(), 'bathrooms'] = lis_df.loc[lis_df['bathrooms'].isna(), 'bathrooms_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_df = pd.read_parquet('data/processed/03_reviews.parquet')\n",
    "rev_s = pd.read_parquet('data/processed/04_sentiment_bert.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_df.sort_values('id')[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_s.sort_values('id')[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "len(rev_s['sentiment_score_1_5'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all columns containing 'host_listings' or matching 'host_total_listings_count'\n",
    "host_listing_cols = [col for col in lis_df.columns if 'host_listings' in col or col == 'host_total_listings_count']\n",
    "print(\"Columns containing 'host_listings' or 'host_total_listings_count':\")\n",
    "print(host_listing_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis_df[host_listing_cols][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the three different host listing count columns\n",
    "listing_counts = lis_df[['host_listings_count', 'host_total_listings_count', 'calculated_host_listings_count']]\n",
    "\n",
    "# Find cases where they are all equal\n",
    "all_equal = (listing_counts['host_listings_count'] == listing_counts['host_total_listings_count']) & \\\n",
    "            (listing_counts['host_total_listings_count'] == listing_counts['calculated_host_listings_count'])\n",
    "\n",
    "print(\"Cases where all counts are equal:\", sum(all_equal))\n",
    "print(\"\\nCases where counts differ:\")\n",
    "print(listing_counts[~all_equal].head())\n",
    "print(f\"\\nTotal cases where counts differ: {sum(~all_equal)}\")\n",
    "\n",
    "# Check if host_total_listings_count is always the largest\n",
    "is_largest = (listing_counts['host_total_listings_count'] >= listing_counts['host_listings_count']) & \\\n",
    "             (listing_counts['host_total_listings_count'] >= listing_counts['calculated_host_listings_count'])\n",
    "print(f\"\\nIs host_total_listings_count always the largest? {is_largest.all()}\")\n",
    "\n",
    "if not is_largest.all():\n",
    "    print(\"\\nCases where host_total_listings_count is not the largest:\")\n",
    "    print(listing_counts[~is_largest].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Various types of analyses to understand the data better and to prepare for the database design."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_cols = [col for col in lis_df.columns if col.startswith('yearly')]\n",
    "print(\"Price-related columns:\", price_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis_df['days_since_last_review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_cols = ['total_reviews', 'number_of_reviews', 'reviews_per_month', 'number_of_reviews_l30d', 'yearly_review', 'number_of_reviews_ltm']\n",
    "print(\"Review-related columns from listings:\")\n",
    "print(lis_df[review_cols].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
